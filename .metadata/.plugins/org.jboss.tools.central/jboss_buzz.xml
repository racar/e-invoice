<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>A small update on RichFaces</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/OnMPsWT_4g8/a-small-update-on-richfaces" /><category term="feed_group_name_jbossrichfaces" scheme="searchisko:content:tags" /><category term="feed_name_michpetrov_blog" scheme="searchisko:content:tags" /><category term="richfaces" scheme="searchisko:content:tags" /><author><name>Michal Petrov</name></author><id>searchisko:content:id:jbossorg_blog-a_small_update_on_richfaces</id><updated>2018-04-12T16:36:46Z</updated><published>2018-04-12T16:36:46Z</published><content type="html">&lt;!-- [DocumentBodyStart:b54766e1-c99f-4660-b67e-0c3a901a65b7] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;p&gt;It has now been almost two years since the development of RichFaces ended, however since people are still using it I just want to clear up a few things.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h3&gt;Showcases&lt;/h3&gt;&lt;p&gt;The showcases were down earlier this year, I had to switch hosting and it didn't go as smoothly as expected. &lt;a class="jive-link-external-small" href="http://showcase.richfaces.org/" rel="nofollow"&gt;showcase.richfaces.org&lt;/a&gt; is now back up and should hopefully remain so for at least another year. Showcase for RF 3 is however not coming back, if you want to use it you will have to deploy it locally; it's just not feasible for me to get it up and running. I found out the demos that were hosted at exadel.com are now also down but I have no control over those.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h3&gt;JIRA, forums and other things&lt;/h3&gt;&lt;p&gt;As far as I know there are no plans to shut down the current "infrastructure" (JIRA, source repositories, this whole site). That said I do not recommend using the JIRA, I'm generally ignoring it. If you want to get a hold of me the forum is the best place to do it. You can also try the &lt;a class="jive-link-external-small" href="https://twitter.com/richfaces" rel="nofollow"&gt;RichFaces Twitter&lt;/a&gt; but I don't check it that often.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;That's about it. Should things change I'll post an update. If you have any questions ask in the comments.&lt;/p&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:b54766e1-c99f-4660-b67e-0c3a901a65b7] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/OnMPsWT_4g8" height="1" width="1" alt=""/&gt;</content><summary>It has now been almost two years since the development of RichFaces ended, however since people are still using it I just want to clear up a few things.   Showcases The showcases were down earlier this year, I had to switch hosting and it didn't go as smoothly as expected. showcase.richfaces.org is now back up and should hopefully remain so for at least another year. Showcase for RF 3 is however n...</summary><dc:creator>Michal Petrov</dc:creator><dc:date>2018-04-12T16:36:46Z</dc:date><feedburner:origLink>https://developer.jboss.org/people/michpetrov/blog/2018/04/12/a-small-update-on-richfaces</feedburner:origLink></entry><entry><title>Bringing Coolstore Microservices to the Service Mesh: Part 2–Manual Injection</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/GzMzljKuuIg/" /><category term="Microservices" /><category term="Modern App Dev" /><category term="istio" /><category term="jboss fuse" /><category term="JBoss Middleware" /><category term="microservices" /><category term="OpenShift Container Platform" /><category term="OpenShift Enterprise by Red Hat" /><category term="Red Hat JBoss Enterprise Application Platform" /><category term="Red Hat OpenShift" /><category term="Red Hat OpenShift Application Runtimes" /><category term="service mesh" /><author><name>James Falkner</name></author><id>https://developers.redhat.com/blog/?p=471547</id><updated>2018-04-12T16:12:15Z</updated><published>2018-04-12T16:12:15Z</published><content type="html">&lt;p&gt;&lt;img class=" alignright size-medium wp-image-471597 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/03/combo-1024x570.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/03/combo-300x167.png" alt="Coolstore+Istio Logo" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/03/combo-300x167.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/03/combo-768x427.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/03/combo-1024x570.png 1024w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/p&gt; &lt;p&gt;In the &lt;a href="https://developers.redhat.com/blog/2018/04/05/coolstore-microservices-service-mesh-part-1-exploring-auto-injection/"&gt;first part of this series&lt;/a&gt; we explored the &lt;a href="https://istio.io"&gt;Istio&lt;/a&gt; project and how Red Hat is committed to and actively involved in the project and working to integrate it into Kubernetes and &lt;a href="http://openshift.com"&gt;OpenShift&lt;/a&gt; to bring the benefits of a service mesh to our customers and the wider communities involved. If you want to play with Istio, check out the &lt;a href="https://learn.openshift.com/servicemesh/"&gt;service mesh tutorials on learn.openshift.com&lt;/a&gt;. If you want to install it, follow the &lt;a href="https://istio.io/docs/setup/kubernetes/quick-start.html"&gt;Istio Kubernetes quickstart instructions&lt;/a&gt; and install it on OpenShift 3.7 or later. Also don&amp;#8217;t miss &lt;a href="https://developers.redhat.com/blog/2018/03/06/introduction-istio-makes-mesh-things/"&gt;Don Schenck&amp;#8217;s series of blogs on Istio technology&lt;/a&gt; in general to learn more about it and what Red Hat is doing in this space.&lt;/p&gt; &lt;p&gt;In this post, we will deploy the existing &lt;a href="https://github.com/jbossdemocentral/coolstore-microservice"&gt;Coolstore microservices demo&lt;/a&gt; as a service mesh and start to demonstrate the tangible value you can get out of the system without any major rewrite or rearchitecture of the existing app. We&amp;#8217;ll also improve our project along the way to adhere to Istio (and general microservice) best practices. In the real world, your applications and developers often make bad assumptions or fail to implement best practices, so with this information you can learn something about your own projects. For Coolstore, many of these workarounds will eventually find their way into the source code of the demo.&lt;/p&gt; &lt;p&gt;&lt;span id="more-471547"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Getting Started&lt;/h2&gt; &lt;p&gt;Let&amp;#8217;s assume you already have OpenShift 3.7+ installed (I am using &lt;a href="https://github.com/openshift/origin/releases/tag/v3.9.0-alpha.3"&gt;OpenShift Origin 3.9.0.alpha3&lt;/a&gt; because at press time, OpenShift Container Platform 3.9 has not yet been released). Let&amp;#8217;s further assume you&amp;#8217;ve &lt;a href="https://istio.io/docs/setup/kubernetes/quick-start.html"&gt;installed Istio 0.6.0 or later&lt;/a&gt;, including the Prometheus, Servicegraph, Jaeger, and Grafana plug-ins  (see the shell script installer in the &lt;em&gt;More Reading&lt;/em&gt; section below for instructions on how to install istio and its plug-ins). Verify Istio is installed and running in the &lt;code&gt;istio-system&lt;/code&gt; namespace:&lt;/p&gt; &lt;pre&gt;% oc get pods -n istio-system NAME READY STATUS RESTARTS AGE grafana-89f97d9c-2wtxx 1/1 Running 0 7m istio-ca-59f6dcb7d9-bs9hx 1/1 Running 0 7m istio-ingress-779649ff5b-jw4hg 1/1 Running 0 7m istio-mixer-7f4fd7dff-pct4j 3/3 Running 0 7m istio-pilot-5f5f76ddc8-pvq4d 2/2 Running 0 7m jaeger-deployment-559c8b9b8-klspv 1/1 Running 0 7m prometheus-cf8456855-svpmb 1/1 Running 0 7m servicegraph-59ff5dbbff-7zrfp 1/1 Running 0 7m &lt;/pre&gt; &lt;p&gt;Let&amp;#8217;s get started. Clone the Coolstore repo and then play along:&lt;/p&gt; &lt;pre&gt;% git clone https://github.com/jbossdemocentral/coolstore-microservice&lt;/pre&gt; &lt;p&gt;And make sure you are logged in as a cluster administrator, or you have &lt;em&gt;cluster-admin&lt;/em&gt; privileges, since it&amp;#8217;ll require you to make some policy and permission changes later on. (As mentioned in part 1, this will be fine-tuned in future Istio releases to not require so much privilege and permission.) You can do this by logging in as a cluster administrator, or if you have sudoer privileges, you can add &lt;code&gt;--as=system:admin&lt;/code&gt; to all the &lt;code&gt;oc&lt;/code&gt; commands below.&lt;/p&gt; &lt;h2&gt;Manual Injection of Sidecars&lt;/h2&gt; &lt;p&gt;In part 1, I showed that with sidecar auto-injection, your app&amp;#8217;s pods are automatically festooned with Envoy proxies without ever having to change the application&amp;#8217;s deployments. However, there are issues with it that currently prevent us from using it. For now, we&amp;#8217;ll do manual injection. Manually injecting has the obvious drawback that you have to do the injection, but it has a big benefit as well: you need to do it only once (per release of Istio), and once it&amp;#8217;s done you can check in the results to your source code management system—&lt;a href="https://en.wikipedia.org/wiki/Infrastructure_as_Code"&gt;infrastructure as code&lt;/a&gt; and all that.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s first set a few environment variables in our Linux shell so we can reference them later on. (Just copy and paste all of these commands into your Linux terminal. If you&amp;#8217;re on Windows, &lt;a href="https://www.howtogeek.com/261591/how-to-create-and-run-bash-shell-scripts-on-windows-10/"&gt;there is hope for you&lt;/a&gt;.)&lt;/p&gt; &lt;pre&gt;# Version of Istio we are using ISTIO_VERSION=0.6.0 # The name of the OpenShift project into which you installed Istio. It should # be istio-system as that's what the Istio nstaller creates for you ISTIO_PROJECT=istio-system # Name of project to house our coolstore service mesh COOLSTORE_PROJECT=coolstore-mesh # Location of istio binaries that you downloaded and installed from istio.io ISTIO_HOME=${HOME}/istio-${ISTIO_VERSION} # Location of Coolstore microservice demo repo COOLSTORE_HOME=${HOME}/coolstore-microservice &lt;/pre&gt; &lt;p&gt;The Coolstore Microservice demo uses a lot of &lt;a href="https://www.redhat.com/en/resources/red-hat-jboss-middleware"&gt;JBoss middleware&lt;/a&gt;, so let&amp;#8217;s install the necessary image stream definitions into the &lt;code&gt;openshift&lt;/code&gt; namespace:&lt;/p&gt; &lt;pre&gt;oc create -n openshift -f https://raw.githubusercontent.com/jboss-fuse/application-templates/master/fis-image-streams.json oc create -n openshift -f https://raw.githubusercontent.com/jboss-openshift/application-templates/master/jboss-image-streams.json&lt;/pre&gt; &lt;p&gt;Next, create a project to house the mesh and give the default &lt;em&gt;serviceaccount&lt;/em&gt; within the project the necessary permissions for Istio to do its thing:&lt;/p&gt; &lt;pre&gt;oc new-project $COOLSTORE_PROJECT oc adm policy add-scc-to-user privileged -z default oc adm policy add-scc-to-user anyuid -z default&lt;/pre&gt; &lt;p&gt;Now comes the &lt;em&gt;big bang&lt;/em&gt;. The &lt;a href="https://github.com/jbossdemocentral/coolstore-microservice"&gt;coolstore microservice demo&lt;/a&gt; comes with a giant &lt;a href="https://docs.openshift.org/latest/dev_guide/templates.html"&gt;OpenShift template&lt;/a&gt; that will create the microservices and associated databases in your new project. It will fire off a number of builds that should eventually succeed, but like many real-world projects, ours does not adhere fully to best practices for container-based microservices, so we&amp;#8217;ll need to work around these issues. We will use &lt;code&gt;oc process&lt;/code&gt; to convert the template into a list of Kubernetes objects, and then pass them through the Istio &lt;a href="https://istio.io/docs/reference/commands/istioctl.html#istioctl%20kube-inject"&gt;manual injection CLI&lt;/a&gt;, which will do the same thing as auto-injection, but do it outside of OpenShift itself. Finally, after passing through the manual injector (istioctl kube-inject), the results are sent to OpenShift via &lt;code&gt;oc apply&lt;/code&gt;. You could instead capture the output and save it to your source code management system, but for demo purposes we&amp;#8217;ll just send it directly to OpenShift. Right after deploying Coolstore, we&amp;#8217;ll stop the deployments using &lt;code&gt;oc rollout cancel&lt;/code&gt; to give us a chance to do some hacking before things are up and running:&lt;/p&gt; &lt;pre&gt;oc process -f ${COOLSTORE_HOME}/openshift/coolstore-template.yaml | \ ${ISTIO_HOME}/bin/istioctl kube-inject -f - | \ oc apply -f - for i in $(oc get dc -o name) ; do oc rollout cancel $i oc rollout pause $i done &lt;/pre&gt; &lt;p&gt;At this point, your builds should be progressing (and CPU contributing to the &lt;a href="https://en.wikipedia.org/wiki/Heat_death_of_the_universe"&gt;heat death of the universe&lt;/a&gt;):&lt;/p&gt; &lt;pre&gt;% oc get builds NAME TYPE FROM STATUS STARTED DURATION cart-1 Source Git@f63f51d Running 37 seconds ago catalog-1 Source Git@f63f51d Running 38 seconds ago coolstore-gw-1 Source Git@f63f51d Running 38 seconds ago inventory-1 Source Git@f63f51d Running 38 seconds ago pricing-1 Source Git@f63f51d Running 37 seconds ago rating-1 Source Git@f63f51d Running 37 seconds ago review-1 Source Git@f63f51d Running 37 seconds ago web-ui-1 Source Git@f63f51d Running 38 seconds ago &lt;/pre&gt; &lt;p&gt;You can keep running &lt;code&gt;oc get builds&lt;/code&gt; until the &lt;code&gt;STATUS&lt;/code&gt; column shows &lt;code&gt;Complete&lt;/code&gt;, but you don&amp;#8217;t have to wait for it in order to continue below.&lt;/p&gt; &lt;p&gt;While the builds are progressing (and deployments are cancelled), one of the first best practices this application does NOT follow is naming the service and container ports used. &lt;a href="https://istio.io/docs/setup/kubernetes/sidecar-injection.html#pod-spec-requirements"&gt;Istio currently requires that for services to participate in the service mesh, their exposed TCP ports must be named&lt;/a&gt;, and they must be named starting with &lt;code&gt;http&lt;/code&gt; or &lt;code&gt;https&lt;/code&gt;. Istio can only intelligently route and trace &lt;a href="https://en.wikipedia.org/wiki/Server_Name_Indication"&gt;SNI or equivalent protocols&lt;/a&gt; such as HTTP and HTTPS that have parseable headers indicating the destination host, so by explicitly naming the service and container ports, you are confirming with Istio your service&amp;#8217;s intention to participate. It just so happens that all the Coolstore services bind to port 8080, so let&amp;#8217;s hack the demo and brute-force name all the service ports &lt;code&gt;http&lt;/code&gt; for simplicity:&lt;/p&gt; &lt;pre&gt;for i in $(oc get svc -o name) ; do PATCH=$(mktemp) cat &amp;#60;&amp;#60;EOF &amp;#62; $PATCH spec: ports: - name: http port: 8080 protocol: TCP targetPort: http EOF oc patch $i -p "$(cat $PATCH)" rm -f $PATCH done&lt;/pre&gt; &lt;p&gt;With the above code, all our services&amp;#8217; ports are now &lt;em&gt;named&lt;/em&gt; (with the exception of database service ports, which you&amp;#8217;ll see in the output are skipped)&lt;em&gt;.&lt;/em&gt; We need to do the same for our containers, and we also need to add some sleep time (see part 1 or consult your doctor for an explanation of the need for sleep). Istio&amp;#8217;s intelligent routing can also &lt;a href="https://istio.io/docs/concepts/traffic-management/request-routing.html#service-model-and-service-versions"&gt;operate on service versions&lt;/a&gt;, so you can do things like &lt;a href="https://voxxeddays.com/romania/2018/01/22/istio-on-kubernetes-canaries-chaos-and-dark-launches/"&gt;canary deployments or dark launches&lt;/a&gt; of different versions of a service. So we&amp;#8217;ll add a version specifier of &lt;code&gt;v1&lt;/code&gt; for all services (later, we&amp;#8217;ll do fun things with this). So here&amp;#8217;s the magic hack to do all of that to our DeploymentConfigs:&lt;/p&gt; &lt;pre&gt;for i in $(oc get dc -o name) ; do oc label $i version=v1 DCNAME=$(echo $i | cut -d'/' -f 2) PATCH=$(mktemp) cat &amp;#60;&amp;#60;EOF &amp;#62; $PATCH spec: strategy: customParams: command: - /bin/sh - '-c' - 'sleep 5; echo slept for 5; /usr/bin/openshift-deploy' template: metadata: labels: version: v1 spec: containers: - name: $DCNAME ports: - containerPort: 8080 name: http protocol: TCP EOF oc patch $i -p "$(cat $PATCH)" rm -f $PATCH done&lt;/pre&gt; &lt;p&gt;Next, since this demo is often used on low-powered laptops, by default, we disable (scale to 0 pods) some services. But because we&amp;#8217;re in big bang mode, let&amp;#8217;s turn those services back on:&lt;/p&gt; &lt;pre&gt;for i in rating rating-mongodb review review-postgresql pricing ; do oc scale --replicas=1 dc $i done&lt;/pre&gt; &lt;p&gt;We&amp;#8217;re almost there. The next issue is with &lt;a href="https://developers.redhat.com/products/eap"&gt;JBoss EAP&lt;/a&gt;. Out of the box, when the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.0/html/red_hat_jboss_enterprise_application_platform_for_openshift/"&gt;containerized JBoss EAP image&lt;/a&gt; starts up, it binds its &lt;a href="http://undertow.io/"&gt;Undertow&lt;/a&gt; listeners to a private IP address (the output of &lt;code&gt;hostname -i&lt;/code&gt;). Due to the networking magic of Istio, it expects containers to bind to its public IP address or &lt;code&gt;0.0.0.0&lt;/code&gt; (that is, all interfaces, and it&amp;#8217;s not documented anywhere that I could find). Unfortunately for us, the bind address for JBoss EAP is fixed to always bind to a private IP address on an interface that Istio does not control or proxy, so we have to resort to another hack to work around this. This hack modifies the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.0/html/red_hat_jboss_enterprise_application_platform_for_openshift/"&gt;JBoss EAP S2I builder image&lt;/a&gt;, creating a derived builder image (using the container image format that shall not be named) that we then use to rebuild our JBoss EAP–based inventory microservice so that it binds to &lt;code&gt;0.0.0.0&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;cat &amp;#60;&amp;#60;EOF | oc new-build --name inventory-builder -D - FROM registry.access.redhat.com/jboss-eap-7/eap70-openshift:1.6 RUN sed -i 's/JBOSS_HA_ARGS="-b \${IP_ADDR}/JBOSS_HA_ARGS="-b 0.0.0.0/' /opt/eap/bin/launch/ha.sh EOF&lt;/pre&gt; &lt;p&gt;Wait for it to complete:&lt;/p&gt; &lt;pre&gt;for i in {1..200}; do oc logs -f bc/inventory-builder &amp;#38;&amp;#38; break || sleep 1; done&lt;/pre&gt; &lt;p&gt;And then rebuild the inventory service using S2I:&lt;/p&gt; &lt;pre&gt;oc new-build --name inventory-hack --to='inventory:latest' ${COOLSTORE_PROJECT}/inventory-builder~${COOLSTORE_HOME} --context-dir=inventory-service&lt;/pre&gt; &lt;p&gt;And wait for it to complete:&lt;/p&gt; &lt;pre&gt;for i in {1..200}; do oc logs -f bc/inventory-hack &amp;#38;&amp;#38; break || sleep 1; done&lt;/pre&gt; &lt;p&gt;One final hack to go. We are using &lt;a href="https://developers.redhat.com/products/fuse"&gt;JBoss Fuse&lt;/a&gt; to implement our Coolstore gateway (which fronts all of our microservices and provides aggregated data back to the UI at runtime). Unfortunately, some features of &lt;a href="https://camel.apache.org"&gt;Camel&lt;/a&gt; (most notably the ones we are using to implement our &lt;a href="http://camel.apache.org/aggregator.html"&gt;AggregationStrategy&lt;/a&gt;) &lt;em&gt;strip&lt;/em&gt; HTTP headers when making downstream calls to other services. This will interfere with &lt;a href="http://opentracing.io/"&gt;proper tracing&lt;/a&gt;, causing the downstream calls to appear as individual &lt;a href="http://opentracing.io/documentation/"&gt;traces&lt;/a&gt; with a single &lt;a href="http://opentracing.io/documentation/"&gt;span&lt;/a&gt; rather than as a single trace containing aggregated spans representing the downstream calls. Proper tracing comes relatively free with the Istio+Prometheus+Jaeger combination so popular these days, and there&amp;#8217;s a lot of value that can be extracted when tracing works, so let&amp;#8217;s hack around this limitation by modifying the source code to the Coolstore gateway to preserve the headers.&lt;/p&gt; &lt;p&gt;This hack assumes you have &lt;a href="https://maven.apache.org/download.cgi"&gt;Maven 3.3.9+ installed&lt;/a&gt;, because it will do an in-place edit of the source using &lt;code&gt;sed&lt;/code&gt;, then do a local rebuild of the hacked source code with Maven, and finally kick off an OpenShift S2I binary rebuild of the service on your local machine:&lt;/p&gt; &lt;pre&gt;sed -i.bak 's/return original;/original.getOut().setHeaders(original.getIn().getHeaders()); return original;/g' \ $COOLSTORE_HOME/coolstore-gw/src/main/java/com/redhat/coolstore/api_gateway/ProductGateway.java mvn -f $COOLSTORE_HOME/coolstore-gw clean package -DskipTests -Dfabric8.skip -e -B oc new-build --name coolstore-gw-hack --to='coolstore-gw:latest' --image fis-java-openshift:2.0 --strategy source --binary oc start-build coolstore-gw-hack --from-file=${COOLSTORE_HOME}/coolstore-gw/target/coolstore-gw.jar --follow &lt;/pre&gt; &lt;p&gt;One other best practice that Coolstore fails to follow is to declare all of the exposed ports in containers that you wish to access. Istio&amp;#8217;s proxy will proxy traffic only to named and declared ports, so if your containers are listening on undeclared or unnamed ports, you won&amp;#8217;t be able to access them, even from within the running container, because Istio transparently intercepts all traffic and passes traffic only on named ports. So in this case, our Coolstore gateway has failed to declare port 8081 (the port on which its &lt;a href="https://docs.openshift.org/latest/dev_guide/application_health.html"&gt;health probes&lt;/a&gt; are exposed), so the health checks will fail. So for now, let&amp;#8217;s disable the Coolstore gateway health check (which in itself is a bad practice, and should be eventually fixed in Coolstore itself):&lt;/p&gt; &lt;pre&gt;oc set probe dc/coolstore-gw --readiness --liveness --remove&lt;/pre&gt; &lt;h2&gt;The Final Step&lt;/h2&gt; &lt;p&gt;Wow; that&amp;#8217;s a lot of hacking. With our newly minted and Istio-ified project, it&amp;#8217;s time to redeploy everything. We&amp;#8217;ll use &lt;code&gt;oc rollout&lt;/code&gt; to do this for all of our deployments:&lt;/p&gt; &lt;pre&gt;for i in $(oc get dc -o name) ; do oc rollout resume $i oc rollout latest $i done&lt;/pre&gt; &lt;p&gt;Wait for the redeployments to complete:&lt;/p&gt; &lt;pre&gt;for i in $(oc get dc -o name) ; do   oc rollout status -w $i done&lt;/pre&gt; &lt;p&gt;If the above command reports timeouts, just rerun the &lt;code&gt;for&lt;/code&gt; loop until all deployments report success.&lt;/p&gt; &lt;p&gt;Ordinarily at this point, once all the deployments complete, you could access the UI of Coolstore directly, but we will use the built-in &lt;a href="https://istio.io/docs/tasks/traffic-management/ingress.html"&gt;Istio Ingress component&lt;/a&gt; so that we can fully control routing of the incoming requests and generate respectable distributed traces from the start of the requests:&lt;/p&gt; &lt;pre&gt;cat &amp;#60;&amp;#60;EOF | oc create -f - apiVersion: extensions/v1beta1 kind: Ingress metadata: name: coolstore-ingress annotations: kubernetes.io/ingress.class: "istio" spec: backend: serviceName: web-ui servicePort: http rules: - http: paths: - path: /api/* backend: serviceName: coolstore-gw servicePort: http EOF&lt;/pre&gt; &lt;p&gt;This will set up &lt;a href="https://istio.io/docs/tasks/traffic-management/ingress.html"&gt;Istio Ingress&lt;/a&gt; to route requests for &lt;code&gt;/api/*&lt;/code&gt; to our Coolstore gateway, and all other requests will just go to the web UI front end. You will access the application through the Ingress route installed in the &lt;code&gt;istio-system&lt;/code&gt; project (you did run &lt;code&gt;oc expose svc/istio-ingress -n istio-system&lt;/code&gt;, right?)&lt;/p&gt; &lt;p&gt;After everything is rebuilt and all the deployments are successfully rolled out, you should be able to access the Coolstore UI through the Istio Ingress service URL in your browser, which you can generate with this command:&lt;/p&gt; &lt;pre&gt;echo "CoolStore URL: http://$(oc get route istio-ingress -n ${ISTIO_PROJECT} --template='{{ .spec.host }}')"&lt;/pre&gt; &lt;p&gt;&lt;img class=" alignright size-medium wp-image-471607 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/03/Screen-Shot-2018-03-20-at-9.35.15-AM-1024x460.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/03/Screen-Shot-2018-03-20-at-9.35.15-AM-1024x460.png" alt="CoolStore Web UI Screenshot" width="640" height="288" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/03/Screen-Shot-2018-03-20-at-9.35.15-AM-1024x460.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/03/Screen-Shot-2018-03-20-at-9.35.15-AM-300x135.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/03/Screen-Shot-2018-03-20-at-9.35.15-AM-768x345.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;p&gt;You can also access the web consoles of various services such as Prometheus and Grafana. Run these commands and then copy/paste the URLs into your browser to verify that everything is working:&lt;/p&gt; &lt;pre&gt;echo "Primary web frontend URL: http://$(oc get route istio-ingress -n ${ISTIO_PROJECT} --template='{{ .spec.host }}')" echo "D3 force layout service graph: http://$(oc get route servicegraph -n ${ISTIO_PROJECT} --template='{{ .spec.host }}')/force/forcegraph.html?time_horizon=5m&amp;#38;filter_empty=true" echo "Example Prometheus query: http://$(oc get route prometheus -n ${ISTIO_PROJECT} --template='{{ .spec.host }}')/graph?g0.range_input=30m&amp;#38;g0.expr=istio_request_count&amp;#38;g0.tab=0" echo "Grafana Istio Dashboard: http://$(oc get route grafana -n ${ISTIO_PROJECT} --template='{{ .spec.host }}')/d/1/istio-dashboard?refresh=5s&amp;#38;orgId=1" echo "Jaeger Tracing Console: http://$(oc get route jaeger-query -n ${ISTIO_PROJECT} --template='{{ .spec.host }}')"&lt;/pre&gt; &lt;p&gt;We will explore these in the next post, but feel free to play around, access the page, generate some load, and inspect the results.&lt;/p&gt; &lt;p&gt;For added fun and value, access the &lt;em&gt;Web front-end URL&lt;/em&gt; a few times in your browser, and then check out the &lt;em&gt;D3 Force Layout endpoint&lt;/em&gt; above. It should look something like this:&lt;/p&gt; &lt;p&gt;&lt;img class=" alignright size-medium wp-image-471617 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/03/Screen-Shot-2018-03-20-at-9.33.36-AM-1024x956.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/03/Screen-Shot-2018-03-20-at-9.33.36-AM-1024x956.png" alt="Service Graph of Coolstore screenshot" width="640" height="598" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/03/Screen-Shot-2018-03-20-at-9.33.36-AM-1024x956.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/03/Screen-Shot-2018-03-20-at-9.33.36-AM-300x280.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/03/Screen-Shot-2018-03-20-at-9.33.36-AM-768x717.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/03/Screen-Shot-2018-03-20-at-9.33.36-AM.png 1478w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;p&gt;The diagram is pretty confusing, because some of the non-HTTP/S accesses (for example, to databases) aren&amp;#8217;t properly linked to the services calling them because Istio cannot interpret these calls. But you can, for example, see that the coolstore-gw makes several downstream calls to other services (inventory, catalog, rating, cart) and these will also show up as proper traces and spans in Jaeger.&lt;/p&gt; &lt;h2&gt;Summary and Observations&lt;/h2&gt; &lt;p&gt;This is a quick way to see a visualization of the service dependencies and confirm that the gateway is indeed accessing the underlying microservices. Some observations:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;You should name all of your container and service ports. You may have noticed in the hacks above we brute-force named all services on port 8080 as &lt;code&gt;http&lt;/code&gt;, but non-HTTP services (most notably PostgreSQL and MongoDB, both of which use non-HTTP protocols) were skipped/ignored. These services cannot participate in the service mesh because Istio currently cannot route these services.&lt;/li&gt; &lt;li&gt;Containerized JBoss EAP has a limitation that we worked around.&lt;/li&gt; &lt;li&gt;JBoss Fuse has an unfortuate side effect for HTTP headers that we worked around.&lt;/li&gt; &lt;li&gt;Manual injection is most likely better than auto-injection in production because you can capture it in infrastructure source code.&lt;br /&gt; Auto-injection is great for demos (once this issue is resolved).&lt;/li&gt; &lt;li&gt;There is HUGE value in Istio+OpenShift for existing apps, whether they use microservices or not.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In the next part of this series, we&amp;#8217;ll explore additional value you can get out of Istio+OpenShift for existing applications, and we&amp;#8217;ll even detect and fix a few issues in our distributed microservice application using the power of Istio service mesh and Red Hat technology. Stay tuned!&lt;/p&gt; &lt;h2&gt;More Reading&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/04/05/coolstore-microservices-service-mesh-part-1-exploring-auto-injection/"&gt;Bringing Coolstore microservices to the Service Mesh Part 1: Automatic Injection&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://gist.github.com/jamesfalkner/ff51aa7e259d9f9c02fd79be757ef12c"&gt;A runnable shell script gist of all of the above hacks including Istio installation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://blog.christianposta.com/tags/#istio"&gt;Christian Posta on Istio&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/03/06/introduction-istio-makes-mesh-things/"&gt;Introduction to Istio; It Makes A Mesh Of Things, by Don Schenck&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/tag/istio/"&gt;Red Hat Developer Blogs on Istio&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F12%2Fbringing-coolstore-microservices-to-the-service-mesh-part-2-manual-injection%2F&amp;#38;linkname=Bringing%20Coolstore%20Microservices%20to%20the%20Service%20Mesh%3A%20Part%202%E2%80%93Manual%20Injection" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F12%2Fbringing-coolstore-microservices-to-the-service-mesh-part-2-manual-injection%2F&amp;#38;linkname=Bringing%20Coolstore%20Microservices%20to%20the%20Service%20Mesh%3A%20Part%202%E2%80%93Manual%20Injection" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F12%2Fbringing-coolstore-microservices-to-the-service-mesh-part-2-manual-injection%2F&amp;#38;linkname=Bringing%20Coolstore%20Microservices%20to%20the%20Service%20Mesh%3A%20Part%202%E2%80%93Manual%20Injection" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F12%2Fbringing-coolstore-microservices-to-the-service-mesh-part-2-manual-injection%2F&amp;#38;linkname=Bringing%20Coolstore%20Microservices%20to%20the%20Service%20Mesh%3A%20Part%202%E2%80%93Manual%20Injection" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F12%2Fbringing-coolstore-microservices-to-the-service-mesh-part-2-manual-injection%2F&amp;#38;linkname=Bringing%20Coolstore%20Microservices%20to%20the%20Service%20Mesh%3A%20Part%202%E2%80%93Manual%20Injection" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F12%2Fbringing-coolstore-microservices-to-the-service-mesh-part-2-manual-injection%2F&amp;#38;linkname=Bringing%20Coolstore%20Microservices%20to%20the%20Service%20Mesh%3A%20Part%202%E2%80%93Manual%20Injection" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F12%2Fbringing-coolstore-microservices-to-the-service-mesh-part-2-manual-injection%2F&amp;#38;linkname=Bringing%20Coolstore%20Microservices%20to%20the%20Service%20Mesh%3A%20Part%202%E2%80%93Manual%20Injection" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F12%2Fbringing-coolstore-microservices-to-the-service-mesh-part-2-manual-injection%2F&amp;#38;linkname=Bringing%20Coolstore%20Microservices%20to%20the%20Service%20Mesh%3A%20Part%202%E2%80%93Manual%20Injection" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F12%2Fbringing-coolstore-microservices-to-the-service-mesh-part-2-manual-injection%2F&amp;#38;title=Bringing%20Coolstore%20Microservices%20to%20the%20Service%20Mesh%3A%20Part%202%E2%80%93Manual%20Injection" data-a2a-url="https://developers.redhat.com/blog/2018/04/12/bringing-coolstore-microservices-to-the-service-mesh-part-2-manual-injection/" data-a2a-title="Bringing Coolstore Microservices to the Service Mesh: Part 2–Manual Injection"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/12/bringing-coolstore-microservices-to-the-service-mesh-part-2-manual-injection/"&gt;Bringing Coolstore Microservices to the Service Mesh: Part 2&amp;#8211;Manual Injection&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/GzMzljKuuIg" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In the first part of this series we explored the Istio project and how Red Hat is committed to and actively involved in the project and working to integrate it into Kubernetes and OpenShift to bring the benefits of a service mesh to our customers and the wider communities involved. If you want to play with [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/12/bringing-coolstore-microservices-to-the-service-mesh-part-2-manual-injection/"&gt;Bringing Coolstore Microservices to the Service Mesh: Part 2&amp;#8211;Manual Injection&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/04/12/bringing-coolstore-microservices-to-the-service-mesh-part-2-manual-injection/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">471547</post-id><dc:creator>James Falkner</dc:creator><dc:date>2018-04-12T16:12:15Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/04/12/bringing-coolstore-microservices-to-the-service-mesh-part-2-manual-injection/</feedburner:origLink></entry><entry><title>An API Journey: From Idea to Deployment the Agile Way–Part I</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/FJct-BVpn54/" /><category term="Microservices" /><category term="Modern App Dev" /><category term="3scale" /><category term="API" /><category term="ci/cd" /><category term="design" /><category term="microservices" /><category term="mock" /><category term="OpenShift Container Platform" /><category term="testing" /><author><name>Laurent Broudoux</name></author><id>https://developers.redhat.com/blog/?p=474577</id><updated>2018-04-11T18:35:09Z</updated><published>2018-04-11T18:35:09Z</published><content type="html">&lt;p&gt;&lt;span style="font-weight: 400;"&gt;The goal of this series of posts is to describe a proposed approach for an &lt;strong&gt;agile API delivery process&lt;/strong&gt;. It will cover not only the development part but also the design, the tests, the delivery, and the management in production. You will learn how to use mocking to speed up development and break dependencies, use the contract-first approach for defining tests that will harden your implementation, protect the exposed API through a management gateway and, finally, secure deliveries using a CI/CD pipeline.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;I coauthored this series with Nicolas Massé, who is also a Red Hatter. This series is based on our own real-life experience from our work with the Red Hat customers we’ve met, as well as from my previous position as SOA architect at a large insurance company. This series is a translation of a typical use case we run during workshops or events such as APIdays.&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Background&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;As IT becomes a core competency for enterprises in order to keep a fast pace of innovation, most companies are now turning into software companies. And they are in the process of rethinking the way they are building and running IT to prepare for the explosion of new digital services to come. This trend leads to modern software architecture paradigms such as APIs and microservices.&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Because API management solutions are becoming mainstream, it has gotten easier to securely expose APIs to the world. However, doing this isn&amp;#8217;t a complete solution. The whole API lifecycle should go agile too in order to stay relevant. Paradoxically, this difficult to do because new a service-based architecture makes dependencies skyrocket.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Thus, &lt;strong&gt;it’s time to think of a new way to deliver APIs—mocking and testing included—to simplify and accelerate the shipping&lt;/strong&gt; of production-ready APIs backed by microservices. &lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Concrete Use Case&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Before we dig in, let’s examine a use case that will help illustrate this approach through an example: the use case of ACME Inc., a local brewery. ACME produces, stores, and distributes beers to its beloved customers, and the whole process is managed in-house.&lt;/span&gt;&lt;/p&gt; &lt;figure id="attachment_477727" style="max-width: 1024px" class="wp-caption aligncenter"&gt;&lt;img class="wp-image-477727 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/acme-inc-situation-1024x475.png" alt="Acme Inc. situation" width="1024" height="475" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/acme-inc-situation-1024x475.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/acme-inc-situation-300x139.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/acme-inc-situation-768x356.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;figcaption class="wp-caption-text"&gt;(Creative Commons licensed icons by Laymik from Noun Project)&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;The increasing competition and the growing demand of the customer base are forcing ACME to rethink its distribution model. Namely, the distribution will be left to independent resellers that could sell beers locally, online or on-site. The main challenge is how to open up the information system so that independent resellers can discover the beer catalog, check inventory, and so on. This can be done through the exposition of an API, of course.&lt;/span&gt;&lt;/p&gt; &lt;address&gt; &lt;figure id="attachment_477737" style="max-width: 1024px" class="wp-caption aligncenter"&gt;&lt;img class="wp-image-477737 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/acme-inc-target-1024x468.png" alt="Acme Inc. target" width="1024" height="468" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/acme-inc-target-1024x468.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/acme-inc-target-300x137.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/acme-inc-target-768x351.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;figcaption class="wp-caption-text"&gt;(Creative Commons licensed icons by Laymik from Noun Project)&lt;/figcaption&gt;&lt;/figure&gt; &lt;/address&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Technologies and Material&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;The technologies we’ll use to help guide ACME Inc. on this journey &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;are:&lt;/span&gt;&lt;/p&gt; &lt;ul&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;API design tool (&lt;/span&gt;&lt;a href="http://www.apicur.io/"&gt;&lt;span style="font-weight: 400;"&gt;Apicurio Studio&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;)&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Mocking and testing tool (&lt;/span&gt;&lt;a href="http://microcks.github.io/"&gt;&lt;span style="font-weight: 400;"&gt;Microcks&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;)&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;API testing and editing tool (&lt;/span&gt;&lt;a href="https://www.getpostman.com/"&gt;&lt;span style="font-weight: 400;"&gt;Postman&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;)&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Service development framework (&lt;/span&gt;&lt;a href="https://projects.spring.io/spring-boot/"&gt;&lt;span style="font-weight: 400;"&gt;Spring Boot&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;)&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Deployment/CI-CD platform (&lt;/span&gt;&lt;a href="https://kubernetes.io/"&gt;&lt;span style="font-weight: 400;"&gt;Kubernetes&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;/&lt;/span&gt;&lt;a href="https://www.openshift.com/"&gt;&lt;span style="font-weight: 400;"&gt;OpenShift&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;)&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;API management tool (&lt;/span&gt;&lt;a href="https://www.3scale.net/"&gt;&lt;span style="font-weight: 400;"&gt;3scale&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;)&lt;/span&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;You might want just read this series, but if you want to go further by replaying the whole use-case demonstration, all the material for that (source code, scripts, setup procedures) can be found in this GitHub repository: &lt;/span&gt;&lt;a href="https://github.com/microcks/api-lifecycle/tree/master/beer-catalog-demo"&gt;&lt;span style="font-weight: 400;"&gt;https://github.com/microcks/api-lifecycle/tree/master/beer-catalog-demo&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;.&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Milestone 0: API Ideation&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Although most API lifecycle definitions start with the design phase and best practices promote a contract-first approach, we all know that it is really hard to start from scratch with API contract design. It’s usually helpful to have a sandbox to test what future APIs should look like. A sandbox allows us to play and illustrate API methods and resources. It should us allow to rapidly test and share different designs for an API.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class="aligncenter wp-image-477337 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-ideation-300x166.png" alt="API ideation stage" width="300" height="166" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-ideation-300x166.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-ideation-768x426.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-ideation-1024x567.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-ideation.png 1238w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;We can see different approaches regarding tooling for this phase.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;The “local” approach consists of using a local tool that is dedicated to simulation. Some tools such as &lt;/span&gt;&lt;a href="https://hoverfly.io/"&gt;&lt;span style="font-weight: 400;"&gt;Hoverfly&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; shine at this, because they are able to use local JSON file definitions to simulate an API. However, these tools are mostly targeting developers and their “local” nature make it hard to easily share and tests multiple designs in the mid- or long-term.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;We prefer a “team” approach that we think makes more sense in an enterprise context. A ready-to-use platform can allow us to host and share different tests. This is one of the purposes of &lt;/span&gt;&lt;a href="http://microcks.github.io/"&gt;&lt;span style="font-weight: 400;"&gt;Microcks&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;, a communication and runtime tool for mocking and testing. Microcks can be easily set up on Kubernetes or OpenShift and provides a “back end as a service” feature called &lt;em&gt;dynamic service&lt;/em&gt;.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Just give it the name and the version of your API, and it generates a basic CRUD REST API for you. For our ACME use case, we will create the &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;Beer Catalog API&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400;"&gt; on version &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;0.1&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400;"&gt; to allow us to play with &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;beer&lt;/span&gt;&lt;span style="font-weight: 400;"&gt; resources.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class="aligncenter wp-image-477617 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-generic-service-creation-1024x797.png" alt="Microcks generic service creation" width="640" height="498" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-generic-service-creation-1024x797.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-generic-service-creation-300x233.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-generic-service-creation-768x598.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-generic-service-creation.png 1308w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Dynamic endpoints for your new API are instantly made available for you. The details page for your dynamic service gives you information about the operations made available as well as the endpoint URL.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class="aligncenter wp-image-477627 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-generic-service-vizualisation-1024x752.png" alt="Microcks generic API visualization" width="1024" height="752" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-generic-service-vizualisation-1024x752.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-generic-service-vizualisation-300x220.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-generic-service-vizualisation-768x564.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;You’re now able to start using this sample API and recording new &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;beer&lt;/span&gt;&lt;span style="font-weight: 400;"&gt; resources within the sandbox by appending the Mock URL to the Microcks base URL :&lt;/span&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;$ curl -X POST 'http://microcks.example.com/dynarest/Beer%20Catalog%20API/0.1/beer' -H 'Content-type: application/json' -d '{"name": "Rodenbach", "country": "Belgium", "type": "Brown ale", "rating": 4.2}' $ curl -X POST 'http://microcks.example.com/dynarest/Beer%20Catalog%20API/0.1/beer' -H 'Content-type: application/json' -d '{"name": "Westmalle Triple", "country": "Belgium", "type": "Trappist", "rating": 3.8}' $ curl -X POST 'http://microcks.example.com/dynarest/Beer%20Catalog%20API/0.1/beer' -H 'Content-type: application/json' -d '{"name": "Weissbier", "country": "Germany", "type": "Wheat", "rating": 4.1}'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;You can check the created resources from the details page. Now everyone who has access to Microcks is also able to review your sample API and the recorded resources.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class="aligncenter wp-image-477637 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-generic-api-resources-1024x777.png" alt="Microcks generic API resources" width="1024" height="777" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-generic-api-resources-1024x777.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-generic-api-resources-300x228.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-generic-api-resources-768x582.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;You’re also able to query resources using different methods. &lt;/span&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;$ curl 'http://microcks.example.com/dynarest/Beer%20Catalog%20API/0.1/beer/' [{ "name" : "Rodenbach", "country" : "Belgium", "type" : "Brown ale", "rating" : 4.2, "id" : "5aa14cef6ba84900019abe9d" }, { "name" : "Westmalle Triple", "country" : "Belgium", "type" : "Trappist", "rating" : 3.8, "id" : "5aa14cf66ba84900019abe9f" }, { "name" : "Weissbier", "country" : "Germany", "type" : "Wheat", "rating" : 4.1, "id" : "5aa14cfc6ba84900019abea0" }] $ curl 'http://microcks.example.com/dynarest/Beer%20Catalog%20API/0.1/beer/5aa14cfc6ba84900019abea0' { "name" : "Weissbier", "country" : "Germany", "type" : "Wheat", "rating" : 4.1, "id" : "5aa14cfc6ba84900019abea0" } $ curl 'http://microcks.example.com/dynarest/Beer%20Catalog%20API/0.1/beer' -H 'Content-type: application/json' -d '{"country": "Belgium"}' [{ "name" : "Rodenbach", "country" : "Belgium", "type" : "Brown ale", "rating" : 4.2, "id" : "5aa14cef6ba84900019abe9d" }, { "name" : "Westmalle Triple", "country" : "Belgium", "type" : "Trappist", "rating" : 3.8, "id" : "5aa14cf66ba84900019abe9f" }]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Microcks provides you with a complete sandbox for iterating, testing different resources representations, sharing them and—most importantly—allowing their integration with some consumer apps for real-life tests. The sandbox gives also helpful samples of resources for the following design phase.&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Milestone 1: API Contract Design&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;The purpose of this phase is to create an API contract artifact covering the technical and syntactic definition of the future API. A contract provides a clear description of the API methods and custom resources manipulated. It represents the cornerstone of a service-based architecture, and we’ll see later in this series how it can be help speed up things and assess future implementations.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Different attempts at standardization the last few years have finally made OpenAPI Specification (formerly the Swagger Specification) emerge as the standard to use. It promotes YAML and JSON as the de facto languages for specifying a contract.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class="aligncenter wp-image-477647 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-design-300x166.png" alt="API design stage" width="300" height="166" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-design-300x166.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-design-768x425.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-design-1024x567.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-design.png 1260w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Here again, you can choose different paths regarding tooling. We still prefer the “team” approach that enables collaborative practices when designing an API contract. Moreover, we’ve found that a team approach helps with building a repository of the dozens of API contracts an enterprise may govern.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="http://www.apicur.io/"&gt;&lt;span style="font-weight: 400;"&gt;Apicurio Studio&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; provides an online collaborative editor for API contracts. It’s a WYSIWYG editor that simplifies API design by providing immediate feedback on compliance with the OpenAPI Specification.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class="aligncenter wp-image-477697 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/apicurio-dashboard-1024x583.png" alt="APIcurio dashboard" width="1024" height="583" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/apicurio-dashboard-1024x583.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/apicurio-dashboard-300x171.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/apicurio-dashboard-768x437.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Apicurio Studio provides a dashboard and facilities for browsing your APIs through tags, importing, or creating brand new API definitions. For our ACME use case, we will create a new &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;Beer Catalog API&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400;"&gt; with a version &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;0.9&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400;"&gt;. Thanks to our previous sandbox tests, ACME was able to precisely define its needs and requires only API methods for browsing the beer catalog.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class="aligncenter wp-image-477707 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/apicurio-api-details-1024x582.png" alt="APIcurio API details" width="1024" height="582" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/apicurio-api-details-1024x582.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/apicurio-api-details-300x171.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/apicurio-api-details-768x437.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;ACME has also been able to detail the definition of the &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;beer&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400;"&gt; resource: identifying the mandatory and the optional attributes of the data model.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;&lt;img class="aligncenter wp-image-477717 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/apicurio-beer-resource-1024x583.png" alt="APIcurio beer resource" width="1024" height="583" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/apicurio-beer-resource-1024x583.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/apicurio-beer-resource-300x171.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/apicurio-beer-resource-768x437.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;All these edit operations are made easily with validation on the fly. Then everything can be saved and versioned into a Git repository. If you want to have a look at the final result, check our copy: &lt;/span&gt;&lt;a href="https://github.com/microcks/api-lifecycle/blob/master/beer-catalog-demo/api-contracts/beer-catalog-api-swagger.json"&gt;&lt;span style="font-weight: 400;"&gt;https://github.com/microcks/api-lifecycle/blob/master/beer-catalog-demo/api-contracts/beer-catalog-api-swagger.json&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Milestone 2  Expectations and Request/Response Samples&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;This stage is usually neglected or ignored when building service-based architecture applications. One mistake people usually make is starting right away with the implementation without taking the small amount of time needed for this step. However—and this was introduced in &lt;/span&gt;&lt;a href="https://blog.openshift.com/mocking-microservices-made-easy-microcks/"&gt;&lt;span style="font-weight: 400;"&gt;another blog post&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;—service contractualization sampling is a strategic step because it allows you to parallelize the development of both the provider and consumers of services and it enables efficient contract testing of your API.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class="aligncenter wp-image-477757 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-sampling-300x174.png" alt="API sampling stage" width="300" height="174" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-sampling-300x174.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-sampling-768x446.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-sampling-1024x594.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-sampling.png 1244w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;While it’s technically feasible to mock from a contract, we think it’s better to use representative samples to get the most of the business logic. Request/response samples expertly illustrate common and edge cases of the future API. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;This stage should also be dedicated to the explicitly defining business expectations that cannot be described using only a technical contract. We can easily use sampling to set up explicit assertions about what response is expected for an incoming request.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;The typical illustration of such a rule is that of the filtered query. Imagine you are offering an API that enables searching items using filters; all the response items should have their values specified as criteria. This may sound obvious but in reality, implementations may easily fail to fulfill this expectation. Another typical use case in financial services is the requirement of a minimum age for subscribing to or purchasing a product. Using sampling and expectations, it is really easy to describe that use case and the message that should appear if the minimum age is not met.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;A simple and efficient tool for doing that is &lt;/span&gt;&lt;a href="https://www.getpostman.com/"&gt;&lt;span style="font-weight: 400;"&gt;Postman&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;. This is because we’re dealing with a modern REST API, but the same principle would apply with legacy SOAP web services by using &lt;/span&gt;&lt;a href="https://www.soapui.org/"&gt;&lt;span style="font-weight: 400;"&gt;SoapUI&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; tooling. Using Postman, we’ll be able to describe real-world requests and responses and then save anything as a JSON file called a &lt;em&gt;collection&lt;/em&gt;. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;For our ACME use case, for example, we first import the OpenAPI Specification we previously created with Apicurio. Then, it is really easy to add some examples for specifying what a response to a “&lt;/span&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;Get beers having the available status&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400;"&gt;” request should look like.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class="aligncenter wp-image-477767 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/postman-samples-1024x771.png" alt="Postman samples" width="640" height="482" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/postman-samples-1024x771.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/postman-samples-300x226.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/postman-samples-768x578.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;We can also specify expectations with Postman using its tests. Tests are not defined specifically for a sample but globally at the method level. Thus, it condenses all the common, edge, and exception cases of a method. Tests are specified using JavaScript snippets.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;In our ACME example, we want to check the filtered query case we described above. This can be done easily by defining a new inline schema definition that restricts the value of the &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;&lt;code&gt;status&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400;"&gt; attribute to the value that is expected.&lt;/span&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;var expectedStatus = globals["status"]; var jsonData = JSON.parse(responseBody); var schema = { "type": "array", "items": { "type": "object", "properties": { "name": { "type": "string" }, "country": { "type": "string" }, "type": { "type": "string" }, "rating": { "type": "number" }, "status": { "type": "string", "enum": [expectedStatus] } } } }; tests["Valid status in response"] = tv4.validate(jsonData, schema); &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;All this information is saved within the collection, which can be later exported and versioned in Git. It’s definitely a good practice to version everything. It also helps other people to contribute sample data and expectations in a &lt;/span&gt;&lt;a href="https://martinfowler.com/articles/consumerDrivenContracts.html"&gt;&lt;span style="font-weight: 400;"&gt;consumer-driven contract&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; way.&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400;"&gt;Key Takeaways&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;So far, we have seen how ACME has started its API journey through the first three stages:&lt;/span&gt;&lt;/p&gt; &lt;ul&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Ideation to mature their needs using a sandbox.&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Contract design to specify the methods, documentation, and data structures of the API.&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400;"&gt;&lt;span style="font-weight: 400;"&gt;Sampling as an extra step allowing the communication of real-life samples and expectations. We&amp;#8217;ll see that it is also an enabler for parallelized development and automated testing.&lt;/span&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Stay tuned for part II in which you will learn how to deploy a mock from the defined examples and much more.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fapi-journey-idea-deployment-agile-part1%2F&amp;#38;linkname=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20I" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fapi-journey-idea-deployment-agile-part1%2F&amp;#38;linkname=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20I" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fapi-journey-idea-deployment-agile-part1%2F&amp;#38;linkname=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20I" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fapi-journey-idea-deployment-agile-part1%2F&amp;#38;linkname=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20I" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fapi-journey-idea-deployment-agile-part1%2F&amp;#38;linkname=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20I" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fapi-journey-idea-deployment-agile-part1%2F&amp;#38;linkname=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20I" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fapi-journey-idea-deployment-agile-part1%2F&amp;#38;linkname=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20I" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fapi-journey-idea-deployment-agile-part1%2F&amp;#38;linkname=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20I" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fapi-journey-idea-deployment-agile-part1%2F&amp;#38;title=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20I" data-a2a-url="https://developers.redhat.com/blog/2018/04/11/api-journey-idea-deployment-agile-part1/" data-a2a-title="An API Journey: From Idea to Deployment the Agile Way–Part I"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/11/api-journey-idea-deployment-agile-part1/"&gt;An API Journey: From Idea to Deployment the Agile Way&amp;#8211;Part I&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/FJct-BVpn54" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;The goal of this series of posts is to describe a proposed approach for an agile API delivery process. It will cover not only the development part but also the design, the tests, the delivery, and the management in production. You will learn how to use mocking to speed up development and break dependencies, use [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/11/api-journey-idea-deployment-agile-part1/"&gt;An API Journey: From Idea to Deployment the Agile Way&amp;#8211;Part I&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/04/11/api-journey-idea-deployment-agile-part1/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">474577</post-id><dc:creator>Laurent Broudoux</dc:creator><dc:date>2018-04-11T18:35:09Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/04/11/api-journey-idea-deployment-agile-part1/</feedburner:origLink></entry><entry><title>Red Hat Summit 2018: Getting Started with Modern Application Development</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/kvUkV0iz6GQ/" /><category term="Events" /><category term="Red Hat Summit" /><category term="cloud native development" /><category term="Developer Events" /><category term="microservice" /><category term="reactive programming" /><category term="red hat summit" /><category term="Red Hat Summit 2018" /><author><name>Mike Guerette</name></author><id>https://developers.redhat.com/blog/?p=484137</id><updated>2018-04-11T10:55:21Z</updated><published>2018-04-11T10:55:21Z</published><content type="html">&lt;p&gt;Are you interested in writing cloud-native applications?  Want to learn about building reactive microservices? Would you like to find out how to quickly get started with Vert.x, Wildfly Swarm, or Node.js in the cloud with Red Hat OpenShift Application Runtimes? Are you an Enterprise Java developer looking to try new programming paradigms?&lt;/p&gt; &lt;p&gt;&lt;strong&gt;To learn about modern application development, join us at &lt;a href="https://www.redhat.com/en/summit/2018"&gt;Red Hat Summit 2018&lt;/a&gt;&lt;/strong&gt; for sessions such as:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://agenda.summit.redhat.com/SessionDetail.aspx?id=153550"&gt;&lt;span style="font-weight: 400;"&gt;Getting started with cloud-native apps&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://agenda.summit.redhat.com/SessionDetail.aspx?id=157103"&gt;Improve developer productivity with Red Hat OpenShift Application Runtimes&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://agenda.summit.redhat.com/SessionDetail.aspx?id=154247"&gt;&lt;span style="font-weight: 400;"&gt;5 minutes to enterprise Node.js on Red Hat OpenShift with Red Hat OpenShift Application Runtimes &lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://agenda.summit.redhat.com/SessionDetail.aspx?id=154522"&gt;&lt;span style="font-weight: 400;"&gt;Be reactive with Red Hat OpenShift Application Runtimes&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://agenda.summit.redhat.com/SessionDetail.aspx?id=154486"&gt;Reactive data pipelines on OpenShift with Eclipse Vert.x&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;span style="font-weight: 400;"&gt;&lt;a href="https://agenda.summit.redhat.com/SessionDetail.aspx?id=154270"&gt;Eclipse MicroProfile with WildFly Swarm&lt;/a&gt; &lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://agenda.summit.redhat.com/SessionDetail.aspx?id=154710"&gt;Low-risk mono to microservices: Istio, Teiid, and Spring Boot&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://agenda.summit.redhat.com/SessionDetail.aspx?id=154237"&gt;5 ways Red Hat OpenShift enhances application development&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://agenda.summit.redhat.com/SessionDetail.aspx?id=154399"&gt;Upgrade your developer powers with Kubernetes and OpenShift&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;h2&gt;Session Highlights&lt;/h2&gt; &lt;p&gt;&lt;span id="more-484137"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h3&gt;&lt;strong&gt;&lt;a href="https://agenda.summit.redhat.com/SessionDetail.aspx?id=157103"&gt;Improve developer productivity with Red Hat OpenShift Application Runtimes&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; &lt;a id="MainContent_HubbSessionDetail_sessionSpeakersListView_A1_0" href="https://agenda.summit.redhat.com/SpeakerDetail.aspx?id=367172"&gt;John Clingan&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt;&lt;/p&gt; &lt;p class="profileBiography"&gt;Developers are being asked to learn a lot in a short period of time. They are moving from monolithic architectures to microservices, from application servers to container platforms, from one application runtime to another, and from an agile methodology to DevOps. This can introduce a lot of complexity.&lt;/p&gt; &lt;p class="profileBiography"&gt;Red Hat OpenShift Application Runtimes combines WildFly Swarm, Spring Boot, Eclipse Vert.x, and Node.js into a single product that makes developing with these runtimes a natural experience on OpenShift.&lt;/p&gt; &lt;p class="profileBiography"&gt;In this session, we&amp;#8217;ll show you how developers can become rapidly productive by following a prescriptive path provided by Red Hat OpenShift Application Runtimes.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;hr /&gt; &lt;h3&gt;&lt;strong&gt;&lt;a href="https://agenda.summit.redhat.com/SessionDetail.aspx?id=153550"&gt;Getting started with cloud-native apps&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Speakers:  &lt;/strong&gt;&lt;a id="MainContent_HubbSessionDetail_sessionSpeakersListView_A1_0" href="https://agenda.summit.redhat.com/SpeakerDetail.aspx?id=365685"&gt;Siamak Sadeghianfar&lt;/a&gt;, &lt;a id="MainContent_HubbSessionDetail_sessionSpeakersListView_A1_1" href="https://agenda.summit.redhat.com/SpeakerDetail.aspx?id=365688"&gt;James Falkner&lt;/a&gt; , &lt;a id="MainContent_HubbSessionDetail_sessionSpeakersListView_A1_2" href="https://agenda.summit.redhat.com/SpeakerDetail.aspx?id=365699"&gt;Thomas Qvarnström&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt;&lt;/p&gt; &lt;div id="MainContent_HubbSessionDetail_sessionBiography" class="section"&gt; &lt;p class="profileBiography"&gt;This hands-on lab on cloud-native apps will introduce the key concepts of modern application development using microservices runtimes and frameworks. In this lab, you&amp;#8217;ll learn how to use the microservices runtimes included in Red Hat OpenShift Application Runtimes—such as Spring Boot, WildFly Swarm, and Vert.x—to build a cloud-native application. We&amp;#8217;ll also share how to automate build, configuration management, and deployment of your cloud-native apps using the application life-cycle management capabilities of Red Hat OpenShift.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;/div&gt; &lt;hr /&gt; &lt;h3&gt;&lt;strong&gt;&lt;a href="https://agenda.summit.redhat.com/SessionDetail.aspx?id=154247"&gt;5 minutes to enterprise Node.js on Red Hat OpenShift with Red Hat OpenShift Application Runtimes&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Speakers: &lt;/strong&gt;&lt;a id="MainContent_HubbSessionDetail_sessionSpeakersListView_A1_0" href="https://agenda.summit.redhat.com/SpeakerDetail.aspx?id=366308"&gt;Jay Balunas&lt;/a&gt;, &lt;a id="MainContent_HubbSessionDetail_sessionSpeakersListView_A1_1" href="https://agenda.summit.redhat.com/SpeakerDetail.aspx?id=366448"&gt;Lance Ball&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt;&lt;/p&gt; &lt;p class="profileBiography"&gt;JavaScript has always played an important role in the browser, and now its use in enterprise server-side development has exploded with Node.js. Its reactive architecture and lightweight design makes it an ideal technology for the containerized microservices architectures you’ve been hearing so much about.&lt;/p&gt; &lt;p class="profileBiography"&gt;What does this mean for your enterprise? Where does it fit, and how can Red Hat OpenShift Application Runtimes help you benefit from this technology while still using a Platform-as-a-Service model?&lt;/p&gt; &lt;p class="profileBiography"&gt;We’ll answer these questions and more as we demonstrate how quickly you can setup a non-trivial, enterprise-grade Node.js application on Red Hat OpenShift. We’ll explore how to integrate with other open source technologies, such as Istio, and discuss strategies for your Node.js development and deployment pipleline, including canary and blue/green deployment strategies.&lt;/p&gt; &lt;hr /&gt; &lt;h3&gt;&lt;strong&gt;&lt;a href="https://agenda.summit.redhat.com/SessionDetail.aspx?id=154522"&gt;Be reactive with Red Hat OpenShift Application Runtimes&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Speakers:&lt;/strong&gt; &lt;a id="MainContent_HubbSessionDetail_sessionSpeakersListView_A1_0" href="https://agenda.summit.redhat.com/SpeakerDetail.aspx?id=366003"&gt;Jeremy Davis&lt;/a&gt;, &lt;a id="MainContent_HubbSessionDetail_sessionSpeakersListView_A1_1" href="https://agenda.summit.redhat.com/SpeakerDetail.aspx?id=366703"&gt;Rodney Russ&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;This session presents how to develop reactive microservices on Red Hat OpenShift. The reactive movement proposes a way to build distributed systems, infusing asynchrony at the heart of the application. Reactive microservices are more responsive, robust, and interactive. They efficiently use the CPU and memory, making them perfectly suited for the cloud and containers.&lt;/p&gt; &lt;p&gt;However, becoming reactive is challenging. How do you exchange messages, handle concurrent requests asynchronously, process streams, and develop asynchronous code?&lt;/p&gt; &lt;p&gt;The reactive facet of Red Hat OpenShift Application Runtimes offers everything you need to build such a system. Based on Eclipse Vert.x—a toolkit to build reactive distributed systems, it enables the development of reactive microservices on top of OpenShift. Vert.x combines an asynchronous execution model, reactive eXtensions, and a thrilling ecosystem. It’s also incredibly flexible—whether it&amp;#8217;s an API gateway, sophisticated web applications, or a high-volume event processing, Vert.x is a great fit.&lt;/p&gt; &lt;hr /&gt; &lt;h3&gt;&lt;strong&gt;&lt;a href="https://agenda.summit.redhat.com/SessionDetail.aspx?id=154486"&gt;Reactive data pipelines on OpenShift with Eclipse Vert.x&lt;/a&gt;&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Speakers:&lt;/strong&gt; &lt;a id="MainContent_HubbSessionDetail_sessionSpeakersListView_A1_0" href="https://agenda.summit.redhat.com/SpeakerDetail.aspx?id=366224"&gt;Clement Escoffier&lt;/a&gt;, &lt;a id="MainContent_HubbSessionDetail_sessionSpeakersListView_A1_1" href="https://agenda.summit.redhat.com/SpeakerDetail.aspx?id=366598"&gt;Marius Bogoevici&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt;&lt;/p&gt; &lt;div id="MainContent_HubbSessionDetail_sessionBiography" class="section"&gt; &lt;p class="profileBiography"&gt;Modern applications are data intensive and deal with large volumes of data from a variety of heterogeneous sources. Use cases are becoming more complex as well—for example, combining IoT, analytics, and traditional enterprise applications in a unified data pipeline. In this scenario, data is flowing continuously. How do you handle this data? How do you deal with a large number of concurrent clients sending data continuously to your application? How can you manage heterogeneous, ever-changing data?&lt;/p&gt; &lt;p class="profileBiography"&gt;In this session, we&amp;#8217;ll share how reactive data pipelines provide a resilient and elastic backbone to face the data flow and get the job done. We&amp;#8217;ll present how applying reactive principles to data pipelines provides a flexible, responsive way to integrate data ingestion and processing scenarios in a microservices-based architecture. This solution integrates Red Hat OpenShift Application Runtimes—specifically its reactive facet, Vert.x—Red Hat AMQ, and Apache Kafka.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;hr /&gt; &lt;h3&gt;&lt;strong&gt;&lt;a href="https://agenda.summit.redhat.com/SessionDetail.aspx?id=154270"&gt;Eclipse MicroProfile with WildFly Swarm&lt;/a&gt; &lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;&lt;strong&gt;Speakers:&lt;/strong&gt; &lt;a id="MainContent_HubbSessionDetail_sessionSpeakersListView_A1_0" href="https://agenda.summit.redhat.com/SpeakerDetail.aspx?id=366285"&gt;Ken Finnigan&lt;/a&gt;, &lt;a id="MainContent_HubbSessionDetail_sessionSpeakersListView_A1_1" href="https://agenda.summit.redhat.com/SpeakerDetail.aspx?id=366308"&gt;Jay Balunas&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Abstract:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;What if there was a way you could take advantage of the latest microservices architectures by using many of the developers and skills you already have? In this session, we’ll show you how with Eclipse MicroProfile and Red Hat’s implementation, WildFly Swarm. We will discuss all the cool features it allows you to easily use, such as fault tolerance and metrics, and we will explain current roadmap plans.&lt;/p&gt; &lt;p&gt;We will also include a demo that showcases what’s possible with Eclipse MicroProfile, utilizing the existing specifications and built with WildFly Swarm as the implementation. We will develop a simple microservice that integrates metrics, health checks, configuration, fault tolerance, open API, tracing, and type-safe REST clients. By the end of the session, attendees will have a better understanding of Eclipse MicroProfile and how to develop to it with WildFly Swarm.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;hr /&gt; &lt;hr /&gt; &lt;h2&gt;Don&amp;#8217;t miss Red Hat Summit 2018&lt;/h2&gt; &lt;p&gt;&lt;a href="https://www.redhat.com/en/summit/2018"&gt;&lt;strong&gt;Red Hat Summit 2018&lt;/strong&gt;&lt;/a&gt; is May 8th &amp;#8211; 10th in San Francisco, CA at the Moscone Center.  Register early to save on a full conference pass.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://agenda.summit.redhat.com/"&gt;List of all sessions&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://agenda.summit.redhat.com/?Application%20development=2"&gt;All Application development sessions&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://agenda.summit.redhat.com/?Cloud-native%20application%20development=4"&gt;Cloud-native application development sessions&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://agenda.summit.redhat.com/?Red+Hat+OpenShift+Application+Runtimes=9"&gt;Sessions on Red Hat OpenShift Application Runtimes&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://agenda.summit.redhat.com/?OpenShift.io=9"&gt;Sessions on Red Hat OpenShift.io&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fred-hat-summit-2018-getting-started-with-modern-application-development%2F&amp;#38;linkname=Red%20Hat%20Summit%202018%3A%20Getting%20Started%20with%20Modern%20Application%20Development" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fred-hat-summit-2018-getting-started-with-modern-application-development%2F&amp;#38;linkname=Red%20Hat%20Summit%202018%3A%20Getting%20Started%20with%20Modern%20Application%20Development" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fred-hat-summit-2018-getting-started-with-modern-application-development%2F&amp;#38;linkname=Red%20Hat%20Summit%202018%3A%20Getting%20Started%20with%20Modern%20Application%20Development" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fred-hat-summit-2018-getting-started-with-modern-application-development%2F&amp;#38;linkname=Red%20Hat%20Summit%202018%3A%20Getting%20Started%20with%20Modern%20Application%20Development" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fred-hat-summit-2018-getting-started-with-modern-application-development%2F&amp;#38;linkname=Red%20Hat%20Summit%202018%3A%20Getting%20Started%20with%20Modern%20Application%20Development" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fred-hat-summit-2018-getting-started-with-modern-application-development%2F&amp;#38;linkname=Red%20Hat%20Summit%202018%3A%20Getting%20Started%20with%20Modern%20Application%20Development" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fred-hat-summit-2018-getting-started-with-modern-application-development%2F&amp;#38;linkname=Red%20Hat%20Summit%202018%3A%20Getting%20Started%20with%20Modern%20Application%20Development" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fred-hat-summit-2018-getting-started-with-modern-application-development%2F&amp;#38;linkname=Red%20Hat%20Summit%202018%3A%20Getting%20Started%20with%20Modern%20Application%20Development" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F11%2Fred-hat-summit-2018-getting-started-with-modern-application-development%2F&amp;#38;title=Red%20Hat%20Summit%202018%3A%20Getting%20Started%20with%20Modern%20Application%20Development" data-a2a-url="https://developers.redhat.com/blog/2018/04/11/red-hat-summit-2018-getting-started-with-modern-application-development/" data-a2a-title="Red Hat Summit 2018: Getting Started with Modern Application Development"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/11/red-hat-summit-2018-getting-started-with-modern-application-development/"&gt;Red Hat Summit 2018: Getting Started with Modern Application Development&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/kvUkV0iz6GQ" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Are you interested in writing cloud-native applications?  Want to learn about building reactive microservices? Would you like to find out how to quickly get started with Vert.x, Wildfly Swarm, or Node.js in the cloud with Red Hat OpenShift Application Runtimes? Are you an Enterprise Java developer looking to try new programming paradigms? To learn about [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/11/red-hat-summit-2018-getting-started-with-modern-application-development/"&gt;Red Hat Summit 2018: Getting Started with Modern Application Development&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/04/11/red-hat-summit-2018-getting-started-with-modern-application-development/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">484137</post-id><dc:creator>Mike Guerette</dc:creator><dc:date>2018-04-11T10:55:21Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/04/11/red-hat-summit-2018-getting-started-with-modern-application-development/</feedburner:origLink></entry><entry><title>Istio Chaos Engineering: I Meant To Do That</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ecZh9Z1LYsQ/" /><category term="Cloud" /><category term="Containers" /><category term="Red Hat OpenShift Container Platform" /><category term="cloud" /><category term="containers" /><category term="istio" /><category term="OpenShift Container Platform" /><category term="testing" /><author><name>Don Schenck</name></author><id>https://developers.redhat.com/blog/?p=477097</id><updated>2018-04-10T10:55:46Z</updated><published>2018-04-10T10:55:46Z</published><content type="html">&lt;p&gt;If you break things before they break, it&amp;#8217;ll give you a break and they won&amp;#8217;t break.&lt;/p&gt; &lt;p&gt;(Clearly, this is management-level material)&lt;/p&gt; &lt;p&gt;&lt;span id="more-477097"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;[This is part six of a ten-week blog series about &lt;a href="https://istio.io/docs/concepts/what-is-istio/overview.html"&gt;Istio&lt;/a&gt;. Part five can be found &lt;a href="https://developers.redhat.com/blog/2018/04/03/istio-tracing-monitoring/"&gt;here&lt;/a&gt;.]&lt;/p&gt; &lt;p&gt;Testing software isn&amp;#8217;t just challenging, it&amp;#8217;s important. Testing for correctness is one thing (e.g. &amp;#8220;does this function return the correct result?&amp;#8221;), but testing for failures in network reliability (the very first of &lt;a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing"&gt;the eight fallacies of distributed computing&lt;/a&gt;) is quite another task. One of the challenges is to be able to mimic or inject faults into the system. Doing it in your source code means changing the very code you&amp;#8217;re testing, which is impossible. You can&amp;#8217;t test the code without the faults added, but the code you want to test doesn&amp;#8217;t have the faults added. Thus the deadly embrace of fault injection and the introduction of &lt;a href="https://en.wikipedia.org/wiki/Heisenbug"&gt;Heisenbugs&lt;/a&gt; &amp;#8212; defects that disappear when you attempt to observe them.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s see how Istio makes this oh so easy.&lt;/p&gt; &lt;h2&gt;We&amp;#8217;re All Fine Here Now, Thank You &amp;#8230; How Are You?&lt;/h2&gt; &lt;p&gt;Here&amp;#8217;s a scenario: Two pods are running our &amp;#8220;recommendation&amp;#8221; microservice (from our &lt;a href="http://bit.ly/istio-tutorial"&gt;Istio Tutorial&lt;/a&gt;), one labeled &amp;#8220;v1&amp;#8221;, the other labeled &amp;#8220;v2&amp;#8221;. As you can see, everything is working just fine:&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-large wp-image-477907 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/chaos_50_50_split-1024x799.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/chaos_50_50_split-1024x799.png" alt="" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/chaos_50_50_split-1024x799.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/chaos_50_50_split-300x234.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/chaos_50_50_split-768x599.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/chaos_50_50_split.png 1472w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;p&gt;(By the way, the number on the right is simply a counter for each pod)&lt;/p&gt; &lt;p&gt;Everything is working swimmingly. Well&amp;#8230; We can&amp;#8217;t have that now, can we? Let&amp;#8217;s have some fun and break things &amp;#8212; &lt;em&gt;without changing any source code&lt;/em&gt;.&lt;/p&gt; &lt;h2&gt;Give Your Microservice A Break&lt;/h2&gt; &lt;p&gt;Here&amp;#8217;s the content of the yaml file we&amp;#8217;ll use to create an Istio route rule that breaks (503, server error) half the time:&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-large wp-image-477807 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-03-at-3.02.06-PM.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-03-at-3.02.06-PM.png" alt="" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-03-at-3.02.06-PM.png 312w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-03-at-3.02.06-PM-252x300.png 252w" sizes="(max-width: 312px) 100vw, 312px" /&gt;&lt;/p&gt; &lt;p&gt;Notice that we&amp;#8217;re specifying a 503 error be returned 50 percent of the time.&lt;/p&gt; &lt;p&gt;Here&amp;#8217;s another screen capture of a &lt;code&gt;curl&lt;/code&gt; command loop running against the microservices, after we&amp;#8217;ve implemented the route rule (above) to break things. Notice that once it goes into effect, half of the requests result in 503 errors, regardless of which pod (v1 or v2) is the endpoint:&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-large wp-image-477827 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-03-at-2.57.24-PM-1024x794.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-03-at-2.57.24-PM-1024x794.png" alt="" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-03-at-2.57.24-PM-1024x794.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-03-at-2.57.24-PM-300x233.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-03-at-2.57.24-PM-768x595.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-03-at-2.57.24-PM.png 1486w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;p&gt;To restore normal operation, you need to simply delete the route rule; in our case the command is &lt;code&gt;istioctl delete routerule recommendation-503 -n tutorial&lt;/code&gt;. &amp;#8220;Tutorial&amp;#8221; is the name of the Red Hat OpenShift project where this tutorial runs.&lt;/p&gt; &lt;h2&gt;Delay Tactics&lt;/h2&gt; &lt;p&gt;Generating 503 errors is helpful when testing the robustness of your system, but anticipating and handling delays is even more impressive &amp;#8212; and probably more common. A slow response from a microservice is like a poison pill that sickens the entire system. Using Istio, you can test your delay-handling code without changing any of your code. In this first example, we are exaggerating the network latency.&lt;/p&gt; &lt;p&gt;Note that, &lt;em&gt;after&lt;/em&gt; testing, you may need (or desire) to change your code, but this is you being proactive instead of &lt;em&gt;reactive&lt;/em&gt;. This is the proper code-test-feedback-code-test&amp;#8230; loop.&lt;/p&gt; &lt;p&gt;Here&amp;#8217;s a route rule that will&amp;#8230; Well, you know what? Istio is so easy to use, and the yaml file is so easy to understand, I&amp;#8217;ll let it speak for itself. I&amp;#8217;m sure you&amp;#8217;ll immediately see what it does:&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-large wp-image-477887 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-03-at-3.39.29-PM.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-03-at-3.39.29-PM.png" alt="" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-03-at-3.39.29-PM.png 317w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-03-at-3.39.29-PM-258x300.png 258w" sizes="(max-width: 317px) 100vw, 317px" /&gt;&lt;/p&gt; &lt;p&gt;Half the time we&amp;#8217;ll see a seven-second delay. Note that this is not like a sleep command in the source code; Istio is holding the request for seven seconds before completing the round trip. Since Istio supports &lt;a href="https://developers.redhat.com/blog/2018/04/03/istio-tracing-monitoring/"&gt;Jaeger tracing&lt;/a&gt;, we can see the effect in this screen capture of the Jaeger UI. Notice the long-running request toward the upper right of the chart &amp;#8212; it took 7.02 seconds:&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-large wp-image-479267 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-3.55.27-PM.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-3.55.27-PM.png" alt="" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-3.55.27-PM.png 810w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-3.55.27-PM-300x111.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-3.55.27-PM-768x285.png 768w" sizes="(max-width: 810px) 100vw, 810px" /&gt;&lt;/p&gt; &lt;p&gt;This scenario allows you to test and code for network latencies. Of course, removing the route rule removes the delay. Again, I hate to belabor the point, but it&amp;#8217;s so important. We introduced this fault without changing our source code.&lt;/p&gt; &lt;h2&gt;Never Gonna Give You Up&lt;/h2&gt; &lt;p&gt;Another useful Istio feature related to chaos engineering is the ability to retry a service N more times. The thought is this: requesting a service may result in a 503 error, but a retry may work. Perhaps some odd edge case caused the service to fail the first time. Yes, you want to know about that and fix it. In the meantime, let&amp;#8217;s keep our system up and running.&lt;/p&gt; &lt;p&gt;So we want a service to occasionally throw a 503 error, and then have Istio retry the service. Hmmm&amp;#8230; If only there was a way to throw a 503 error without changing our code.&lt;/p&gt; &lt;p&gt;Wait. Istio can do that. We just did that several paragraphs ago.&lt;/p&gt; &lt;p&gt;Using the following file, we&amp;#8217;ll have 503 errors being thrown by our &amp;#8220;recommendation-v2&amp;#8221; service half the time:&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-large wp-image-479487 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.39.51-PM.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.39.51-PM-250x300.png" alt="" width="250" height="300" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.39.51-PM-250x300.png 250w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.39.51-PM.png 616w" sizes="(max-width: 250px) 100vw, 250px" /&gt;&lt;/p&gt; &lt;p&gt;Sure enough, some requests are failing:&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-large wp-image-479497 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.42.08-PM-1024x809.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.42.08-PM-1024x809.png" alt="" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.42.08-PM-1024x809.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.42.08-PM-300x237.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.42.08-PM-768x607.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.42.08-PM.png 1334w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;p&gt;Now we can introduce the Retry feature of Istio, using this nifty configuration:&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-large wp-image-479507 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.43.23-PM.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.43.23-PM.png" alt="" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.43.23-PM.png 309w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.43.23-PM-252x300.png 252w" sizes="(max-width: 309px) 100vw, 309px" /&gt;&lt;/p&gt; &lt;p&gt;We&amp;#8217;ve configured this route rule to retry up to 2-3 times, waiting two seconds between attempts. This should reduce (or hopefully eliminate) 503 errors:&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-large wp-image-479517 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.46.09-PM-1024x822.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.46.09-PM-1024x822.png" alt="" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.46.09-PM-1024x822.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.46.09-PM-300x241.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.46.09-PM-768x616.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.46.09-PM.png 1316w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;p&gt;Just to recap: We have Istio tossing 503 errors for half of the requests, and we also have Istio performing three retries after a 503 error. As a result, everything is A-OK. By not giving up, but by using the Retry, we kept our promise.&lt;/p&gt; &lt;p&gt;Did I mention we&amp;#8217;re doing all this with no changes to our source code? I may have mentioned that. Two Istio route rules were all it took:&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-large wp-image-479527 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.49.09-PM.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.49.09-PM.png" alt="" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.49.09-PM.png 599w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-04-at-4.49.09-PM-300x47.png 300w" sizes="(max-width: 599px) 100vw, 599px" /&gt;&lt;/p&gt; &lt;h2&gt;Never Gonna Let You Down&lt;/h2&gt; &lt;p&gt;Now it&amp;#8217;s time turn around and do the opposite; we want a scenario where we&amp;#8217;re going to wait only a given time span before giving up and deserting our request attempt. In other words, we&amp;#8217;re not going to slow down everything while waiting for one slow service. Instead, we will bail out of the request and use some sort of fallback position. Don&amp;#8217;t worry dear website user&amp;#8230; We won&amp;#8217;t let you down.&lt;/p&gt; &lt;p&gt;Istio allows us to establish a Timeout limit for a request. If the service takes longer than the Timeout, a 504 (Gateway Timeout) error is returned. Again, this is all done via Istio configuration. We did however add a sleep command to our source code (and rebuilt and redeployed the code in a container) to mimic a slow service. There&amp;#8217;s not really a no-touch way around this; we need slow code.&lt;/p&gt; &lt;p&gt;After adding the three-second sleep to our recommendation (v2 image and redeploying the container), we&amp;#8217;ll add the following timeout rule via an Istio route rule:&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-large wp-image-479777 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-05-at-9.44.35-AM.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-05-at-9.44.35-AM.png" alt="" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-05-at-9.44.35-AM.png 312w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-05-at-9.44.35-AM-270x300.png 270w" sizes="(max-width: 312px) 100vw, 312px" /&gt;&lt;/p&gt; &lt;p&gt;As you can see, we&amp;#8217;re giving the recommendation service one second before we return a 504 error. After implementing this route rule (and with the three-second sleep built into our recommendation:v2 service), here&amp;#8217;s what we get:&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone size-large wp-image-479827 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-05-at-10.02.35-AM-1024x812.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-05-at-10.02.35-AM-1024x812.png" alt="" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-05-at-10.02.35-AM-1024x812.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-05-at-10.02.35-AM-300x238.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-05-at-10.02.35-AM-768x609.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/Screen-Shot-2018-04-05-at-10.02.35-AM.png 1326w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;h2&gt;Where Have I Heard This Before?&lt;/h2&gt; &lt;p&gt;Repeating, ad nauseam: we are able to set this timeout function with no changes to our source code. The value here is that you can now write your code to respond to a timeout and easily test it using Istio.&lt;/p&gt; &lt;h2&gt;All Together Now&lt;/h2&gt; &lt;p&gt;Injecting chaos into your system, via Istio, is a powerful way to push your code to the limits and test your robustness. Fallbacks, bulkheads, and circuit breaker patterns are combined with Istio&amp;#8217;s fault injection, delays, retries, and timeouts to support your efforts to build fault-tolerant, cloud-native systems. Using these technologies (combined with &lt;a href="https://www.redhat.com/en/topics/containers/what-is-kubernetes"&gt;Kubernetes&lt;/a&gt; and &lt;a href="https://developers.redhat.com/products/openshift/overview/"&gt;Red Hat OpenShift&lt;/a&gt;), give you the tools needed to move into the future.&lt;/p&gt; &lt;p&gt;And to give yourself a break.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F10%2Fistio-chaos-engineering%2F&amp;#38;linkname=Istio%20Chaos%20Engineering%3A%20I%20Meant%20To%20Do%20That" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F10%2Fistio-chaos-engineering%2F&amp;#38;linkname=Istio%20Chaos%20Engineering%3A%20I%20Meant%20To%20Do%20That" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F10%2Fistio-chaos-engineering%2F&amp;#38;linkname=Istio%20Chaos%20Engineering%3A%20I%20Meant%20To%20Do%20That" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F10%2Fistio-chaos-engineering%2F&amp;#38;linkname=Istio%20Chaos%20Engineering%3A%20I%20Meant%20To%20Do%20That" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F10%2Fistio-chaos-engineering%2F&amp;#38;linkname=Istio%20Chaos%20Engineering%3A%20I%20Meant%20To%20Do%20That" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F10%2Fistio-chaos-engineering%2F&amp;#38;linkname=Istio%20Chaos%20Engineering%3A%20I%20Meant%20To%20Do%20That" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F10%2Fistio-chaos-engineering%2F&amp;#38;linkname=Istio%20Chaos%20Engineering%3A%20I%20Meant%20To%20Do%20That" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F10%2Fistio-chaos-engineering%2F&amp;#38;linkname=Istio%20Chaos%20Engineering%3A%20I%20Meant%20To%20Do%20That" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F10%2Fistio-chaos-engineering%2F&amp;#38;title=Istio%20Chaos%20Engineering%3A%20I%20Meant%20To%20Do%20That" data-a2a-url="https://developers.redhat.com/blog/2018/04/10/istio-chaos-engineering/" data-a2a-title="Istio Chaos Engineering: I Meant To Do That"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/10/istio-chaos-engineering/"&gt;Istio Chaos Engineering: I Meant To Do That&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ecZh9Z1LYsQ" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;If you break things before they break, it&amp;#8217;ll give you a break and they won&amp;#8217;t break. (Clearly, this is management-level material) [This is part six of a ten-week blog series about Istio. Part five can be found here.] Testing software isn&amp;#8217;t just challenging, it&amp;#8217;s important. Testing for correctness is one thing (e.g. &amp;#8220;does this function [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/10/istio-chaos-engineering/"&gt;Istio Chaos Engineering: I Meant To Do That&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/04/10/istio-chaos-engineering/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">477097</post-id><dc:creator>Don Schenck</dc:creator><dc:date>2018-04-10T10:55:46Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/04/10/istio-chaos-engineering/</feedburner:origLink></entry><entry><title>Announcing WildFly Swarm 2018.4.1</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/MAGbTsdfJ1I/announcing-wildfly-swarm-2018-4-1" /><category term="feed_group_name_wildfly_swarm" scheme="searchisko:content:tags" /><category term="feed_name_wildfly_swarm" scheme="searchisko:content:tags" /><author><name>unknown</name></author><id>searchisko:content:id:jbossorg_blog-announcing_wildfly_swarm_2018_4_1</id><updated>2018-04-10T05:00:00Z</updated><published>2018-04-10T05:00:00Z</published><content type="html">&lt;div class="sect1"&gt; &lt;h2 id="_wildfly_swarm_2018_4_1"&gt;WildFly Swarm 2018.4.1&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Beware the Ides of April, and a failed release attempt! But we got there!&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_what_s_new"&gt;What’s New?&lt;/h3&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;JAX-RS Application is no longer generated by default (breaking change)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;MicroProfile "JPA" Hollow jar&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Many MicroProfile related improvements&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Enhanced Swagger integration&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Improved KeyCloak integration&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Lots of other fixes!&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/MAGbTsdfJ1I" height="1" width="1" alt=""/&gt;</content><summary>WildFly Swarm 2018.4.1 Beware the Ides of April, and a failed release attempt! But we got there! What’s New? JAX-RS Application is no longer generated by default (breaking change) MicroProfile "JPA" Hollow jar Many MicroProfile related improvements Enhanced Swagger integration Improved KeyCloak integration Lots of other fixes!</summary><dc:creator>unknown</dc:creator><dc:date>2018-04-10T05:00:00Z</dc:date><feedburner:origLink>https://wildfly-swarm.io/posts/announcing-wildfly-swarm-2018-4-1</feedburner:origLink></entry><entry><title>Hibernate Community Newsletter 07/2018</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/iYJ-xbXwngU/" /><category term="Discussions" scheme="searchisko:content:tags" /><category term="feed_group_name_hibernate" scheme="searchisko:content:tags" /><category term="feed_name_inrelationto" scheme="searchisko:content:tags" /><category term="Hibernate ORM" scheme="searchisko:content:tags" /><category term="newsletter" scheme="searchisko:content:tags" /><author><name>Vlad Mihalcea</name></author><id>searchisko:content:id:jbossorg_blog-hibernate_community_newsletter_07_2018</id><updated>2018-04-10T09:13:56Z</updated><published>2018-04-10T00:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Welcome to the Hibernate community newsletter in which we share blog posts, forum, and StackOverflow questions that are especially relevant to our users.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="articles"&gt;&lt;a class="anchor" href="#articles"&gt;&lt;/a&gt;Articles&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;If you want to use Kotlin with Hibernate, then you should check out &lt;a href="http://www.baeldung.com/kotlin-jpa"&gt;this article&lt;/a&gt;. On the same page, there’s also this &lt;a href="https://github.com/roamingthings/kotlin-jpa-workbench"&gt;GitHub repository&lt;/a&gt; that shows you how to use Kotlin, JPA, and Spring Boot.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;CDC (Change Data Capture) is a very useful technique to push database changes as events to other systems. Debezium is an open-source project aiming to simplify this process, and, in &lt;a href="http://debezium.io/blog/2018/03/08/creating-ddd-aggregates-with-debezium-and-kafka-streams/"&gt;this article&lt;/a&gt;, you will how to create DDD aggregates with Debezium and Kafka Streams.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;When using PostgreSQL, it’s quite common to use a SERIAL column for Primary Keys. However, SERIAL column types have limitations when using JPA and Hibernate. For more details, check out &lt;a href="https://vladmihalcea.com/postgresql-serial-column-hibernate-identity/"&gt;this article&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;There is a great variety of Java connection pool frameworks, so choosing one that fits your application requirements might not be a trivial task. &lt;a href="https://beansroasted.wordpress.com/2017/07/29/connection-pool-analysis/"&gt;This article&lt;/a&gt; shows a very detailed analysis of the most well-known connection pools, so choosing the right framework will be easier after you read it.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Apart from supporting the standard JPA annotation, Hibernate offers many other annotations that allow you to deal with various data access requirements. One such annotation, &lt;code&gt;@Immutable&lt;/code&gt; lets you fetch entities in read-only mode by default. For more details, check out &lt;a href="https://vladmihalcea.com/immutable-entity-jpa-hibernate/"&gt;this article&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;By default, Apache TomEE ships with OpenJPA. However, you can use any JPA provider you want, and &lt;a href="https://fmdojo.wordpress.com/2018/04/03/hibernate-5-2-spatial-jpa-in-apache-tomee-7/"&gt;this article&lt;/a&gt; shows how to set up TomEE to use Hibernate.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Sam Kruglov wrote a very &lt;a href="https://samkruglov.wordpress.com/2018/01/07/json-filtering-with-spring/"&gt;interesting article&lt;/a&gt; about filtering RESTful JSON views with Spring and JPA.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;If you are starting learning Java EE, &lt;a href="https://www.halfastack.com/java-ee-jpa-introduction-i/"&gt;this article&lt;/a&gt; is a very good introduction to Java Persistence API.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;If you are using Criteria API and want to know how to order results, then check out &lt;a href="https://www.thoughts-on-java.org/hibernate-tips-order-by-clause-criteriaquery/"&gt;this article&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="time-to-upgrade"&gt;&lt;a class="anchor" href="#time-to-upgrade"&gt;&lt;/a&gt;Time to upgrade&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;There were two Hibernate project releases since the last newsletter:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://in.relation.to/2018/03/29/hibernate-ogm-5-3-1-Final-released/"&gt;Hibernate OGM 5.3.1.Final is out&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://in.relation.to/2018/03/27/hibernate-validator-609-final-out/"&gt;Hibernate Validator 6.0.9.Final is released&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="questions-and-answers"&gt;&lt;a class="anchor" href="#questions-and-answers"&gt;&lt;/a&gt;Questions and answers&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/43467484/hibernate-caching-and-lazy-loaded-associations/49487615#49487615"&gt;Hibernate Caching and lazy loaded associations&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/retrieving-a-few-records-at-one-time-from-database-with-jpa/432"&gt;Retrieving a few records at one time from the database with JPA&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/30019731/hibernate-jpql-throws-update-delete-queries-cannot-be-typed/30019803#30019803"&gt;Hibernate JPQL throws Update/delete queries cannot be typed&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/entity-loader-does-not-take-into-consideration-a-subsequent-lock-request/467"&gt;Entity Loader does not take into consideration a subsequent lock request &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/do-i-need-hibernate-cfg-xml-if-i-use-jpa/468"&gt;Do I need the &lt;code&gt;hibernate.cfg.xml&lt;/code&gt; if I use JPA?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/avoiding-unnecessary-join-with-many-to-many-relation/465"&gt;Avoiding unnecessary Join with Many-to-many relation&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/27804069/hibernate-mapping-between-postgresql-enum-and-java-enum/46303099#46303099"&gt;Hibernate mapping between PostgreSQL enum and Java enum&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/30288464/when-should-i-use-joincolumn-or-jointable/30292348#30292348"&gt;When should I use &lt;code&gt;@JoinColumn&lt;/code&gt; or &lt;code&gt;@JoinTable&lt;/code&gt;?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/28363625/exclude-entity-field-when-doing-update-with-jpa/28363801#28363801"&gt;How to exclude an entity field when doing an update with JPA&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/97197/what-is-n1-select-query-issue/39696775#39696775"&gt;What is the N+1 SELECT query issue?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/1590422/immutable-vs-entitymutable-false-in-hibernate/49651679#49651679"&gt;&lt;code&gt;@Immutable&lt;/code&gt; vs &lt;code&gt;@Entity(mutable=false)&lt;/code&gt; in Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/where-annotation-does-no-refresh-after-updating-the-child-collection/503"&gt;&lt;code&gt;@Where&lt;/code&gt; annotation does no refresh after updating the child collection&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/33496956/postgresql-stored-procedure-and-hibernate"&gt;PostgreSQL Stored Procedure and Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/28253838/can-i-use-hibernate-for-jta/28260359#28260359"&gt;Can I use Hibernate for JTA?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/iYJ-xbXwngU" height="1" width="1" alt=""/&gt;</content><summary>Welcome to the Hibernate community newsletter in which we share blog posts, forum, and StackOverflow questions that are especially relevant to our users. Articles If you want to use Kotlin with Hibernate, then you should check out this article. On the same page, there’s also this GitHub repository that shows you how to use Kotlin, JPA, and Spring Boot. CDC (Change Data Capture) is a very useful te...</summary><dc:creator>Vlad Mihalcea</dc:creator><dc:date>2018-04-10T00:00:00Z</dc:date><feedburner:origLink>http://in.relation.to/2018/04/10/hibernate-community-newsletter-2018-07/</feedburner:origLink></entry><entry><title>Accessing Data – The Reactive Way</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Ilmh64d6DhY/" /><category term="Java" /><category term="Microservices" /><category term="database" /><category term="future" /><category term="JDBC" /><category term="reactive" /><category term="vert.x" /><author><name>Clement Escoffier</name></author><id>https://developers.redhat.com/blog/?p=478367</id><updated>2018-04-09T18:03:58Z</updated><published>2018-04-09T18:03:58Z</published><content type="html">&lt;p&gt;This is the fourth post of my &amp;#8220;&lt;em&gt;Introduction to &lt;a href="https://vertx.io/"&gt;Eclipse Vert.x&lt;/a&gt;&lt;/em&gt;.&amp;#8221; series. In this article, we are going to see how we can use JDBC in an Eclipse Vert.x application using the asynchronous API provided by the &lt;a href="http://vertx.io/docs/vertx-jdbc-client/java/"&gt;vertx-jdbc-client&lt;/a&gt;. But before diving into JDBC and other SQL subtleties, we are going to talk about Vert.x &lt;code&gt;Futures&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;In &amp;#8220;The Introduction to Vert.x&amp;#8221; Series&lt;/h2&gt; &lt;p&gt;Let’s start by refreshing our memory about the previous articles:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;The &lt;a href="https://developers.redhat.com/blog/2018/03/13/eclipse-vertx-first-application/"&gt;first post&lt;/a&gt; described how to build a vert.x application with Maven and execute unit tests.&lt;/li&gt; &lt;li&gt;The &lt;a href="https://developers.redhat.com/blog/2018/03/22/eclipse-vert-x-application-configuration"&gt;second post&lt;/a&gt; reviewed how this application became configurable.&lt;/li&gt; &lt;li&gt;The &lt;a href="https://developers.redhat.com/blog/2018/03/29/rest-vert-x"&gt;third post&lt;/a&gt; introduced vertx-web, and a collection management application was developed. This application exposes a REST API used by an HTML/JavaScript frontend.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;span id="more-478367"&gt;&lt;/span&gt;In this fourth post we will fix the major flaw of our application: the in-memory back-end. The current application uses an in-memory &lt;code&gt;Map&lt;/code&gt; to store the products (articles). This is very useful as we lose the content every time we restart the application. Let&amp;#8217;s use a database. In this post, we are going to use PostgreSQL, but you can use any database providing a JDBC driver. For instance, our tests are going to use HSQL. Interactions with the database are asynchronous and made using the &lt;code&gt;vertx-jdbc-client&lt;/code&gt;. But before diving into these JDBC and SQL details, let&amp;#8217;s introduce the Vert.x &lt;code&gt;Future&lt;/code&gt; class and explain how it&amp;#8217;s going to make asynchronous coordination much simpler.&lt;/p&gt; &lt;p&gt;The code of this post is available on the &lt;a href="https://github.com/redhat-developer/introduction-to-eclipse-vertx"&gt;Github repo&lt;/a&gt;, in the &lt;code&gt;post-4&lt;/code&gt; directory.&lt;/p&gt; &lt;h2&gt;Asynchronous API&lt;/h2&gt; &lt;p&gt;One of the Eclipse Vert.x characteristics is its asynchronous and non-blocking nature. With an asynchronous API, you don’t wait for a result, but you are notified when this result is ready, the operation has completed&amp;#8230; Just to illustrate this, let’s take a very simple example.&lt;/p&gt; &lt;p&gt;Let’s imagine a &lt;code&gt;retrieve&lt;/code&gt; method. Traditionally, you would use it like this: &lt;code&gt;String r = retrieve()&lt;/code&gt;. This is a synchronous API as the execution continue when for the result has been returned by the &lt;code&gt;retrieve&lt;/code&gt; method. An asynchronous version of this API would be: &lt;code&gt;retrieve(r -&amp;#62; { /* do something with the result */ })&lt;/code&gt;. In this version, you pass a function (&lt;code&gt;Handler&lt;/code&gt; in the Vert.x lingo) called when the result has been computed. This function does not return anything and is called when the result has been computed. For instance, the &lt;code&gt;retrieve&lt;/code&gt; method code could be something like:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; public void retrieve(Handler&amp;#60;String&amp;#62; resultHandler) { fileSystem.read(fileName, res -&amp;#62; { resultHandler.handle(res); }); } &lt;/pre&gt; &lt;p&gt;Just to avoid misconceptions, asynchronous APIs are not about threads. As we can see in the &lt;code&gt;retrieve&lt;/code&gt; example, there are no threads involved and most Vert.x applications are using a very small number of threads while being asynchronous and non-blocking. Also, it&amp;#8217;s important to notice that the method is non-blocking. The &lt;code&gt;retrieve&lt;/code&gt; method may return before the &lt;code&gt;resultHandler&lt;/code&gt; is called.&lt;/p&gt; &lt;p&gt;Asynchronous operations can also &amp;#8230; fail. So, we need a way to encapsulate these failures and forward them to the callback. We can&amp;#8217;t use &lt;code&gt;try-catch&lt;/code&gt; blocks because of the asynchrony. To capture the result or the failure or an operation, Vert.x proposes the &lt;code&gt;AsyncResult&lt;/code&gt; type. Our &lt;code&gt;Handler&lt;/code&gt; does not receive the plain result anymore but an &lt;code&gt;AsyncResult&lt;/code&gt; encapsulating the result in case of success or the error if something bad happens:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; public void retrieve( Handler&amp;#60;AsyncResult&amp;#60;String&amp;#62;&amp;#62; resultHandler) { vertx.fileSystem().readFile(&amp;#34;fileName&amp;#34;, ar -&amp;#62; { if (ar.failed()) { resultHandler.handle( Future.succeededFuture(ar.result().toString())); } else { resultHandler.handle( Future.failedFuture(ar.cause())); } }); } &lt;/pre&gt; &lt;p&gt;Look at the &lt;code&gt;if-else&lt;/code&gt; block. You will see it a lot when using &lt;code&gt;AsyncResult&lt;/code&gt;. I won&amp;#8217;t detail &lt;code&gt;Future&lt;/code&gt; here, it&amp;#8217;s covered a bit later, just be patient. For now, &lt;code&gt;Future.succeededFuture&lt;/code&gt; and &lt;code&gt;Future.failedFuture&lt;/code&gt; are just factory methods creating &lt;code&gt;AsyncResult&lt;/code&gt; instances. On the consumer side, you would do:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; retrieve(ar -&amp;#62; { if (ar.failed()) { // Handle the failure, the exception is // retrieved using ar.cause() Throwable cause = ar.cause(); // ... } else { // Made it, the result is in ar.result() String content = ar.result(); // ... } }); &lt;/pre&gt; &lt;p&gt;So, to summarize, an asynchronous method is a method forwarding its result or failure as a notification, generally calling a callback expecting the result.&lt;/p&gt; &lt;h2&gt;The Asynchronous Coordination Dilemma&lt;/h2&gt; &lt;p&gt;Once you have a set of asynchronous methods, you generally want to orchestrate them:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Sequentially, so calling once another one has completed.&lt;/li&gt; &lt;li&gt;Concurrently, so calling several actions at the same time and being notified when all/one of them have completed.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;For the first case, we would do something like:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; retrieve(ar -&amp;#62; { if (ar.failed()) { // do something to recover } else { String r = ar.result(); // call another async method anotherAsyncMethod(r, ar2 -&amp;#62; { if (ar2.failed()) { //... } else { // ... } }) } }); &lt;/pre&gt; &lt;p&gt;You can quickly spot the issue&amp;#8230; things start getting messy. Nested callbacks reduce code readability, and this was with just two. Imagine dealing with more than that, as we will see later in this post.&lt;/p&gt; &lt;p&gt;For the second type of composition, you can also imagine the difficulty. In each result handler, you need to check whether or not the others have completed or failed and then react accordingly. This leads to convoluted code.&lt;/p&gt; &lt;h2&gt;Future and CompositeFuture (Async Coordination Made Easy)&lt;/h2&gt; &lt;p&gt;To reduce the code complexity, Vert.x proposes a class named &lt;code&gt;Future&lt;/code&gt;. A &lt;code&gt;Future&lt;/code&gt; is an object that encapsulates a result of an action that may, or may not, have occurred yet. Unlike regular Java Future, Vert.x &lt;code&gt;Future&lt;/code&gt; is non-blocking and a &lt;code&gt;Handler&lt;/code&gt; is called when the &lt;code&gt;Future&lt;/code&gt; is completed or &lt;code&gt;failed&lt;/code&gt;. The &lt;code&gt;Future&lt;/code&gt; class implements &lt;code&gt;AsyncResult&lt;/code&gt; as it represents a result computed asynchronously.&lt;/p&gt; &lt;p&gt;&lt;em&gt;A note about Java Future:&lt;/em&gt; Regular Java &lt;code&gt;Future&lt;/code&gt; is blocking. Calling &lt;code&gt;get&lt;/code&gt; blocks the caller thread until the result is received (or a timeout is reached). Vert.x &lt;code&gt;Futures&lt;/code&gt; also have a &lt;code&gt;get&lt;/code&gt; method returning &lt;code&gt;null&lt;/code&gt; if the result is not yet received. They also expect a handler to be attached to them, calling it when the result is received.&lt;/p&gt; &lt;p&gt;Creating a &lt;code&gt;Future&lt;/code&gt; object is done using the &lt;code&gt;Future.future()&lt;/code&gt; factory method:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; Future&amp;#60;Integer&amp;#62; future = Future.future(); future.complete(1); // Completes the Future with a result future.fail(exception); // Fails the Future // To be notified when the future has been completed // or failed future.setHandler(ar -&amp;#62; { // Handler called with the result or the failure, // ar is an AsyncResult }); &lt;/pre&gt; &lt;p&gt;Let&amp;#8217;s revisit our &lt;code&gt;retrieve&lt;/code&gt; method. Instead of taking a callback as a parameter, we can return a &lt;code&gt;Future&lt;/code&gt; object:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; public Future&amp;#60;String&amp;#62; retrieve() { Future&amp;#60;String&amp;#62; future = Future.future(); vertx.fileSystem().readFile(&amp;#34;fileName&amp;#34;, ar -&amp;#62; { if (ar.failed()) { future.failed(ar.cause()); } else { future.complete(ar.result().toString()); } }); return future; } &lt;/pre&gt; &lt;p&gt;As mentioned above, it&amp;#8217;s important to understand that this &lt;code&gt;retrieve&lt;/code&gt; method returns its &lt;code&gt;Future&lt;/code&gt; probably before it receives a value. So, the &lt;code&gt;return future;&lt;/code&gt; statement is executed before it executes &lt;code&gt;future.handle(...)&lt;/code&gt;. Vert.x seasoned developers would have written this code a bit differently:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; public Future&amp;#60;String&amp;#62; retrieve() { Future&amp;#60;String&amp;#62; future = Future.future(); vertx.fileSystem().readFile(&amp;#34;fileName&amp;#34;, ar -&amp;#62; future.handle(ar.map(Buffer::toString))); return future; } &lt;/pre&gt; &lt;p&gt;We are going to cover this API in a few minutes. but first, let&amp;#8217;s look at the caller side, things do not change much. The handler is attached on the returned &lt;code&gt;Future&lt;/code&gt;.&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; retrieve().setHandler(ar -&amp;#62; { if (ar.failed()) { // Handle the failure, the exception is // retrieved using ar.cause() Throwable cause = ar.cause(); // ... } else { // Made it, the result is in ar.result() int r = ar.result(); // ... } }); &lt;/pre&gt; &lt;p&gt;Where things become much easier is when you need to compose asynchronous action. Sequential composition is handled using the &lt;code&gt;compose&lt;/code&gt; method:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; retrieve() .compose(this::anotherAsyncMethod) .setHandler(ar -&amp;#62; { // ar.result is the final result // if any stage fails, ar.cause is // the thrown exception }); &lt;/pre&gt; &lt;p&gt;&lt;code&gt;Future.compose&lt;/code&gt; takes as a parameter a function consuming the result of the previous &lt;code&gt;Future&lt;/code&gt; and returning another &lt;code&gt;Future&lt;/code&gt;. This way you can chain many asynchronous actions.&lt;/p&gt; &lt;p&gt;What about concurrent composition. Let&amp;#8217;s imagine you want to invoke 2 unrelated operations and be notified when both have completed:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; Future&amp;#60;String&amp;#62; future1 = retrieve(); Future&amp;#60;Integer&amp;#62; future2 = anotherAsyncMethod(); CompositeFuture.all(future1, future2) .setHandler(ar -&amp;#62; { // called when either all future have completed // successfully (success), // or one failed (failure) }); &lt;/pre&gt; &lt;p&gt;&lt;code&gt;CompositeFuture&lt;/code&gt; is a companion class simplifying the drastically concurrent composition. &lt;code&gt;all&lt;/code&gt; is not the only operator provided, you can use &lt;code&gt;join&lt;/code&gt;, &lt;code&gt;any&lt;/code&gt;&amp;#8230;&lt;/p&gt; &lt;p&gt;Using &lt;code&gt;Future&lt;/code&gt; and &lt;code&gt;CompositeFuture&lt;/code&gt; make the code much more readable and maintainable. Vert.x also supports RX Java to manage asynchronous composition, this will be covered in another post.&lt;/p&gt; &lt;h2&gt;JDBC Yes, but Asynchronous&lt;/h2&gt; &lt;p&gt;So, now that we have seen some basics about asynchronous APIs and &lt;code&gt;Future&lt;/code&gt;s, let’s have a look to the &lt;code&gt;vertx-jdbc-client&lt;/code&gt;. This Vert.x module lets us interact with a database through a JDBC driver. These interactions are asynchronous, so when you were doing:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; String sql = &amp;#34;SELECT * FROM Products&amp;#34;; ResultSet rs = stmt.executeQuery(sql); &lt;/pre&gt; &lt;p&gt;When you use the &lt;code&gt;vertx-jdbc-client&lt;/code&gt;, it becomes:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; connection.query(&amp;#34;SELECT * FROM Products&amp;#34;, result -&amp;#62; { // do something with the result }); &lt;/pre&gt; &lt;p&gt;This model avoids waiting for the result. You are notified when the result has been retrieved from the database.&lt;/p&gt; &lt;p&gt;&lt;em&gt;A Note on JDBC&lt;/em&gt;: JDBC is a blocking API by default. To interact with the database, Vert.x delegates to a &lt;em&gt;worker&lt;/em&gt; thread. While it&amp;#8217;s asynchronous, it&amp;#8217;s not totally non-blocking. However, the Vert.x ecosystem also provides truly non-blocking clients for MySQL and PostgreSQL.&lt;/p&gt; &lt;p&gt;Let’s now modify our application to use a database to store our products (articles).&lt;/p&gt; &lt;h2&gt;Some Maven Dependencies&lt;/h2&gt; &lt;p&gt;The first things we need to do it to declare two new Maven dependencies in our &lt;code&gt;pom.xml&lt;/code&gt; file:&lt;/p&gt; &lt;pre class="brush: xml; title: ; notranslate"&gt; &amp;#60;dependency&amp;#62; &amp;#60;groupId&amp;#62;io.vertx&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;vertx-jdbc-client&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;${vertx.version}&amp;#60;/version&amp;#62; &amp;#60;/dependency&amp;#62; &amp;#60;dependency&amp;#62; &amp;#60;groupId&amp;#62;org.postgresql&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;postgresql&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;9.4.1212&amp;#60;/version&amp;#62; &amp;#60;/dependency&amp;#62; &lt;/pre&gt; &lt;p&gt;The first dependency provides the &lt;code&gt;vertx-jdbc-client&lt;/code&gt;, while the second one provides the PostgreSQL JDBC driver. If you want to use another database, change this dependency. You will also need to change the JDBC URL and JDBC driver class name in the code.&lt;/p&gt; &lt;h2&gt;Initializing the JDBC Client&lt;/h2&gt; &lt;p&gt;Now that we have added these dependencies, it’s time to create our JDBC client. But it needs to be configured. Edit the &lt;code&gt;src/main/conf/my-application-conf.json&lt;/code&gt; to match the following content:&lt;/p&gt; &lt;pre class="brush: jscript; title: ; notranslate"&gt; { &amp;#34;HTTP_PORT&amp;#34;: 8082, &amp;#34;url&amp;#34;: &amp;#34;jdbc:postgresql://localhost:5432/my_read_list&amp;#34;, &amp;#34;driver_class&amp;#34;: &amp;#34;org.postgresql.Driver&amp;#34;, &amp;#34;user&amp;#34;: &amp;#34;user&amp;#34;, &amp;#34;password&amp;#34;: &amp;#34;password&amp;#34; } &lt;/pre&gt; &lt;p&gt;We add the &lt;code&gt;url&lt;/code&gt;, &lt;code&gt;driver_class&lt;/code&gt;, &lt;code&gt;user&lt;/code&gt; and &lt;code&gt;password&lt;/code&gt; entries. Notice that if you use a different database, the configuration will likely be different.&lt;/p&gt; &lt;p&gt;Now that the configuration is written, we need to create an instance of JDBC client. In the &lt;code&gt;MyFirstVerticle&lt;/code&gt; class, declare a new field &lt;code&gt;JDBCClient jdbc;&lt;/code&gt;, and update the end of the &lt;code&gt;start&lt;/code&gt; method to become:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; ConfigRetriever retriever = ConfigRetriever.create(vertx); retriever.getConfig( config -&amp;#62; { if (config.failed()) { fut.fail(config.cause()); } else { // Create the JDBC client jdbc = JDBCClient.createShared(vertx, config.result(), &amp;#34;My-Reading-List&amp;#34;); vertx .createHttpServer() .requestHandler(router::accept) .listen( // Retrieve the port from the configuration, // default to 8080. config.result().getInteger(&amp;#34;HTTP_PORT&amp;#34;, 8080), result -&amp;#62; { if (result.succeeded()) { fut.complete(); } else { fut.fail(result.cause()); } }); } } ); &lt;/pre&gt; &lt;p&gt;Ok, we have the &lt;em&gt;client&lt;/em&gt; configured with our configuration, we need a connection to the database. This is achieved using the &lt;code&gt;jdbc.getConnection&lt;/code&gt; method that provides its result (the connection) to a &lt;code&gt;Handler&amp;#60;AsyncResult&amp;#62;&lt;/code&gt;. This handler is notified when the connection with the database is established or if something bad happens during the process. While we could use the method directly, let&amp;#8217;s extract the retrieval of a connection to a separate method and returns a &lt;code&gt;Future&lt;/code&gt;:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; private Future&amp;#60;SQLConnection&amp;#62; connect() { Future&amp;#60;SQLConnection&amp;#62; future = Future.future(); // 1 jdbc.getConnection(ar -&amp;#62; // 2 future.handle(ar.map(connection -&amp;#62; // 3 connection.setOptions( new SQLOptions().setAutoGeneratedKeys(true)) // 4 ) ) ); return future; // 5 } &lt;/pre&gt; &lt;p&gt;Let&amp;#8217;s have a deeper look to this method. First we create a &lt;code&gt;Future&lt;/code&gt; object (1) that we return at the end of the method (5). This &lt;code&gt;Future&lt;/code&gt; will be completed or failed depending wether or not we successfully retrieve a connection to the database. This is done in (2). The function we passed to &lt;code&gt;getConnection&lt;/code&gt; receives an &lt;code&gt;AsyncResult&lt;/code&gt;. &lt;code&gt;Future&lt;/code&gt; have a method (&lt;code&gt;handle&lt;/code&gt;) to directly completes or fails based on an &lt;code&gt;AsyncResult&lt;/code&gt;. To &lt;code&gt;handle&lt;/code&gt; is equivalent to:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; if (ar.failed()) { future.failed(ar.cause()); } else { future.complete(ar.result()); } &lt;/pre&gt; &lt;p&gt;just&amp;#8230; shorter.&lt;/p&gt; &lt;p&gt;However, before passing the &lt;code&gt;AsyncResult&lt;/code&gt; to &lt;code&gt;future&lt;/code&gt;, we want to configure the connection to enable the key generation. For this, we use the &lt;code&gt;AsyncResult.map&lt;/code&gt; method. This method creates another instance of &lt;code&gt;AsyncResult&lt;/code&gt; based on the given one and applies a mapper function on the result. If the given one encapsulates a failure, the created one encapsulate the same failure. If the input is a success, the mapper function is applied on the result.&lt;/p&gt; &lt;h2&gt;We Need Articles&lt;/h2&gt; &lt;p&gt;Now that we have a JDBC client, and a way to retrieve a connection to the database it&amp;#8217;s time to insert articles. But because we use a relational database, we first need to create the table. Create the following method:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; private Future&amp;#60;SQLConnection&amp;#62; createTableIfNeeded(SQLConnection connection) { Future&amp;#60;SQLConnection&amp;#62; future = Future.future(); vertx.fileSystem().readFile(&amp;#34;tables.sql&amp;#34;, ar -&amp;#62; { if (ar.failed()) { future.fail(ar.cause()); } else { connection.execute(ar.result().toString(), ar2 -&amp;#62; future.handle(ar2.map(connection)) ); } }); return future; } &lt;/pre&gt; &lt;p&gt;The method also returns a &lt;code&gt;Future&lt;/code&gt;. Attentive readers would spot that this is typically a method we can use in a &lt;code&gt;Future.compose&lt;/code&gt; construct. This method body is quite simple. As usual, we create a &lt;code&gt;Future&lt;/code&gt; and returns it at the end of the body. Then, we read the content of the &lt;code&gt;tables.sql&lt;/code&gt; file and execute the unique statement contained in this file. The &lt;code&gt;execute&lt;/code&gt; method takes the SQL statement as a parameter and invokes the given function with the result. In the handler, we complete or fail the future using the &lt;code&gt;handle&lt;/code&gt; method. In this case, we want to complete the future with the database connection.&lt;/p&gt; &lt;p&gt;So, we need the &lt;code&gt;tables.sql&lt;/code&gt; file. Creates the &lt;code&gt;src/main/resources/tables.sql&lt;/code&gt; file with the following content:&lt;/p&gt; &lt;pre class="brush: sql; title: ; notranslate"&gt; CREATE TABLE IF NOT EXISTS Articles (id SERIAL PRIMARY KEY, title VARCHAR(200) NOT NULL, url VARCHAR(200) NOT NULL) &lt;/pre&gt; &lt;p&gt;Ok, so now we have a connection to the database, and the table. Let&amp;#8217;s insert articles, but only if the database is empty. For this, create the &lt;code&gt;createSomeDataIfNone&lt;/code&gt; and &lt;code&gt;insert&lt;/code&gt; methods:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; private Future&amp;#60;SQLConnection&amp;#62; createSomeDataIfNone(SQLConnection connection) { Future&amp;#60;SQLConnection&amp;#62; future = Future.future(); connection.query(&amp;#34;SELECT * FROM Articles&amp;#34;, select -&amp;#62; { if (select.failed()) { future.fail(select.cause()); } else { if (select.result().getResults().isEmpty()) { Article article1 = new Article(&amp;#34;Fallacies of distributed computing&amp;#34;, &amp;#34;https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing&amp;#34;); Article article2 = new Article(&amp;#34;Reactive Manifesto&amp;#34;, &amp;#34;https://www.reactivemanifesto.org/&amp;#34;); Future &amp;#60;Article&amp;#62; insertion1 = insert(connection, article1, false); Future &amp;#60;Article&amp;#62; insertion2 = insert(connection, article2, false); CompositeFuture.all(insertion1, insertion2) .setHandler(r -&amp;#62; future.handle(r.map(connection))); } else { // Boring... nothing to do. future.complete(connection); } } }); return future; } private Future &amp;#60;Article&amp;#62; insert(SQLConnection connection, Article article, boolean closeConnection) { Future &amp;#60;Article&amp;#62; future = Future.future(); String sql = &amp;#34;INSERT INTO Articles (title, url) VALUES (?, ?)&amp;#34;; connection.updateWithParams(sql, new JsonArray().add(article.getTitle()).add(article.getUrl()), ar -&amp;#62; { if (closeConnection) { connection.close(); } future.handle( ar.map(res -&amp;#62; new Article(res.getKeys().getLong(0), article.getTitle(), article.getUrl())) ); } ); return future; } &lt;/pre&gt; &lt;p&gt;Let&amp;#8217;s start by the end and the &lt;code&gt;insert&lt;/code&gt; method. It follows the same pattern and uses the &lt;code&gt;updateWithParams&lt;/code&gt; method to insert an article into the database. The SQL statement contains parameters injected using a JSON Array. Notice that the order of the parameter matters. When the insertion is done (in the handler), we close the connection if requested (&lt;code&gt;closeConnection&lt;/code&gt; parameter) &amp;#8211; this is because we are going to reuse method later. Finally, we complete or fail the &lt;code&gt;future&lt;/code&gt; with, on success, a new &lt;code&gt;Article&lt;/code&gt; containing the generated id. So, if the insertion failed, we just forward the failure to the future. If the insertion succeeds, we map it to an &lt;code&gt;Article&lt;/code&gt; and complete the future with this value.&lt;/p&gt; &lt;p&gt;Ok, let&amp;#8217;s switch to the &lt;code&gt;createSomeDataIfNone&lt;/code&gt; method. Again same pattern. But here we need a bit of coordination. Indeed, we need to check whether the database is empty first and if so insert two articles. To check if the database is empty, we use &lt;code&gt;connection.query&lt;/code&gt; retrieving all the articles. If the result is not empty, we create two articles that we insert using the &lt;code&gt;insert&lt;/code&gt; method. To execute these two insertions, we use the &lt;code&gt;CompositeFuture&lt;/code&gt; construct. So both actions are executed in concurrently, and when both are done (or one fails) the handler is called. Notice that the connection is not closed.&lt;/p&gt; &lt;h2&gt;Putting These Pieces Together&lt;/h2&gt; &lt;p&gt;It&amp;#8217;s time to assemble these pieces and see how it works. The &lt;code&gt;start&lt;/code&gt; method needs to be updated to execute the following action:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Retrieve the configuration (already done).&lt;/li&gt; &lt;li&gt;When the configuration is retrieved, create the JDBC client (already done).&lt;/li&gt; &lt;li&gt;Retrieve a connection to the database.&lt;/li&gt; &lt;li&gt;With this connection, create the table if they do not exist.&lt;/li&gt; &lt;li&gt;With the same connection, check whether the database contains articles, if not, insert some data.&lt;/li&gt; &lt;li&gt;Close the connection.&lt;/li&gt; &lt;li&gt;Start the HTTP server as we are ready to &lt;em&gt;serve.&lt;/em&gt;&lt;/li&gt; &lt;li&gt;Report the success or failure of the boot process to &lt;code&gt;fut&lt;/code&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Wow&amp;#8230; that&amp;#8217;s a lot of actions. Fortunately, we have implemented almost all the required method in a way we can use &lt;code&gt;Future&lt;/code&gt; composition. In the &lt;code&gt;start&lt;/code&gt; method, replace the end of the code with:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; // Start sequence: // 1 - Retrieve the configuration // |- 2 - Create the JDBC client // |- 3 - Connect to the database (retrieve a connection) // |- 4 - Create table if needed // |- 5 - Add some data if needed // |- 6 - Close connection when done // |- 7 - Start HTTP server // |- 8 - we are done! ConfigRetriever.getConfigAsFuture(retriever) .compose(config -&amp;#62; { jdbc = JDBCClient.createShared(vertx, config, &amp;#34;My-Reading-List&amp;#34;); return connect() .compose(connection -&amp;#62; { Future&amp;#60;Void&amp;#62; future = Future.future(); createTableIfNeeded(connection) .compose(this::createSomeDataIfNone) .setHandler(x -&amp;#62; { connection.close(); future.handle(x.mapEmpty()); }); return future; }) .compose(v -&amp;#62; createHttpServer(config, router)); }).setHandler(fut); &lt;/pre&gt; &lt;p&gt;Don&amp;#8217;t worry about the &lt;code&gt;createHttpServer&lt;/code&gt; method. We will cover it shortly. The code starts by retrieving the configuration and creates the &lt;code&gt;JDBCClient&lt;/code&gt;. Then, we retrieve a database connection and initialize our database. Notice that the connection is close in all cases (even failures). When the database is set up, we start the HTTP server. Finally, when everything is done, we report the result (success or failure) to the &lt;code&gt;fut&lt;/code&gt; telling to Vert.x whether or not we are ready to work.&lt;/p&gt; &lt;p&gt;&lt;em&gt;Note about closing connections&lt;/em&gt;: Don’t forget to close the SQL connection when you are done. The connection will be given back to the connection pool and be recycled.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;createHTTPServer&lt;/code&gt; method is quite simple and follows the same pattern:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; private Future&amp;#60;Void&amp;#62; createHttpServer(JsonObject config, Router router) { Future&amp;#60;Void&amp;#62; future = Future.future(); vertx .createHttpServer() .requestHandler(router::accept) .listen( config.getInteger(&amp;#34;HTTP_PORT&amp;#34;, 8080), res -&amp;#62; future.handle(res.mapEmpty()) ); return future; } &lt;/pre&gt; &lt;p&gt;Notice the &lt;code&gt;mapEmpty&lt;/code&gt;. The method returns a &lt;code&gt;Future&lt;/code&gt;, as we don&amp;#8217;t care of the HTTP Server. To create an &lt;code&gt;AsyncResult&lt;/code&gt; from an &lt;code&gt;AsyncResult&lt;/code&gt; use the &lt;code&gt;mapEmpty&lt;/code&gt; method, discarding the encapsulated result.&lt;/p&gt; &lt;h2&gt;Implementing the REST API On Top of JDBC&lt;/h2&gt; &lt;p&gt;So, at this point, we have everything setup, but our API is still relying on our in-memory back-end. It&amp;#8217;s time to re-implement our REST API on top of JDBC. But first, we need some utility methods focusing on the interaction with the database. These methods have been extracted to ease the understanding.&lt;/p&gt; &lt;p&gt;First, let&amp;#8217;s add the &lt;code&gt;query&lt;/code&gt; method:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; private Future&amp;#60;List &amp;#60;Article&amp;#62;&amp;#62; query(SQLConnection connection) { Future&amp;#60;List &amp;#60;Article&amp;#62;&amp;#62; future = Future.future(); connection.query(&amp;#34;SELECT * FROM articles&amp;#34;, result -&amp;#62; { connection.close(); future.handle( result.map(rs -&amp;#62; rs.getRows().stream() .map(Article::new) .collect(Collectors.toList())) ); } ); return future; } &lt;/pre&gt; &lt;p&gt;This method uses again the same pattern: it creates a &lt;code&gt;Future&lt;/code&gt; object and returns it. The future is completed or failed when the underlying action completes or fails. Here the action is a database query. The method executes the query and upon success, for each &lt;em&gt;row&lt;/em&gt; creates a new &lt;code&gt;Article&lt;/code&gt;. Also, notice that we close the connection regardless the success or failure of the query. It&amp;#8217;s important to release the connection, so it can be recycled.&lt;/p&gt; &lt;p&gt;In the same vein, let&amp;#8217;s implement &lt;code&gt;queryOne&lt;/code&gt;:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; private Future &amp;#60;Article&amp;#62; queryOne(SQLConnection connection, String id) { Future &amp;#60;Article&amp;#62; future = Future.future(); String sql = &amp;#34;SELECT * FROM articles WHERE id = ?&amp;#34;; connection.queryWithParams(sql, new JsonArray().add(Integer.valueOf(id)), result -&amp;#62; { connection.close(); future.handle( result.map(rs -&amp;#62; { List&amp;#60;JsonObject&amp;#62; rows = rs.getRows(); if (rows.size() == 0) { throw new NoSuchElementException( &amp;#34;No article with id &amp;#34; + id); } else { JsonObject row = rows.get(0); return new Article(row); } }) ); }); return future; } &lt;/pre&gt; &lt;p&gt;This method uses &lt;code&gt;queryWithParams&lt;/code&gt; to inject the article id in the query. In the result handler, there is a bit more work as we need to check if the article has been found. If not, we throw a &lt;code&gt;NoSuchElementException&lt;/code&gt; that would fail the &lt;code&gt;future&lt;/code&gt;. This lets us generate &lt;code&gt;404&lt;/code&gt; responses.&lt;/p&gt; &lt;p&gt;We have done queries, we need methods to update and delete. Here they are:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; private Future&amp;#60;Void&amp;#62; update(SQLConnection connection, String id, Article article) { Future&amp;#60;Void&amp;#62; future = Future.future(); String sql = &amp;#34;UPDATE articles SET title = ?, url = ? WHERE id = ?&amp;#34;; connection.updateWithParams(sql, new JsonArray().add(article.getTitle()) .add(article.getUrl()) .add(Integer.valueOf(id) ), ar -&amp;#62; { connection.close(); if (ar.failed()) { future.fail(ar.cause()); } else { UpdateResult ur = ar.result(); if (ur.getUpdated() == 0) { future.fail(new NoSuchElementException( &amp;#34;No article with id &amp;#34; + id)); } else { future.complete(); } } }); return future; } private Future&amp;#60;Void&amp;#62; delete(SQLConnection connection, String id) { Future&amp;#60;a&amp;#62; future = Future.future(); String sql = &amp;#34;DELETE FROM Articles WHERE id = ?&amp;#34;; connection.updateWithParams(sql, new JsonArray().add(Integer.valueOf(id)), ar -&amp;#62; { connection.close(); if (ar.failed()) { future.fail(ar.cause()); } else { if (ar.result().getUpdated() == 0) { future.fail( new NoSuchElementException( &amp;#34;No article with id &amp;#34; + id)); } else { future.complete(); } } }); return future; } &lt;/pre&gt; &lt;p&gt;They are very similar and follow the same pattern (again!).&lt;/p&gt; &lt;p&gt;That&amp;#8217;s great but it does not implement our REST API. So, let&amp;#8217;s focus on this now. Just to refresh our mind, here are the methods we need to update:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;getAll&lt;/code&gt; returns all the articles.&lt;/li&gt; &lt;li&gt;&lt;code&gt;addOne&lt;/code&gt; inserts a new article. Article details are given in the request body.&lt;/li&gt; &lt;li&gt;&lt;code&gt;deleteOne&lt;/code&gt; deletes a specific article. The id is given as a &lt;em&gt;path parameter&lt;/em&gt;.&lt;/li&gt; &lt;li&gt;&lt;code&gt;getOne&lt;/code&gt; provides the JSON representation of a specific article. The id is given as a &lt;em&gt;path parameter&lt;/em&gt;.&lt;/li&gt; &lt;li&gt;&lt;code&gt;updateOne&lt;/code&gt; updates a specific article. The id is given as a &lt;em&gt;path parameter&lt;/em&gt;. The new details are in the request body.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Because we have extracted the database interactions in their own method, implementing this method is straightforward. For instance, the &lt;code&gt;getAll&lt;/code&gt; method is:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; private void getAll(RoutingContext rc) { connect() .compose(this::query) .setHandler(ok(rc)); } &lt;/pre&gt; &lt;p&gt;We retrieve a connection using the &lt;code&gt;connect&lt;/code&gt; method. Then we compose (sequential composition) this with the &lt;code&gt;query&lt;/code&gt; method, and we attach a handler. This handler is &lt;code&gt;ok(rc)&lt;/code&gt; which is provided in the &lt;code&gt;ActionHelper&lt;/code&gt; class. It basically provides the JSON representation or manages the error responses (&lt;code&gt;500&lt;/code&gt;, &lt;code&gt;404&lt;/code&gt;).&lt;/p&gt; &lt;p&gt;Following the same pattern, the other methods are implemented as follows:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; private void addOne(RoutingContext rc) { Article article = rc.getBodyAsJson().mapTo(Article.class); connect() .compose(connection -&amp;#62; insert(connection, article, true)) .setHandler(created(rc)); } private void deleteOne(RoutingContext rc) { String id = rc.pathParam(&amp;#34;id&amp;#34;); connect() .compose(connection -&amp;#62; delete(connection, id)) .setHandler(noContent(rc)); } private void getOne(RoutingContext rc) { String id = rc.pathParam(&amp;#34;id&amp;#34;); connect() .compose(connection -&amp;#62; queryOne(connection, id)) .setHandler(ok(rc)); } private void updateOne(RoutingContext rc) { String id = rc.request().getParam(&amp;#34;id&amp;#34;); Article article = rc.getBodyAsJson().mapTo(Article.class); connect() .compose(connection -&amp;#62; update(connection, id, article)) .setHandler(noContent(rc)); } &lt;/pre&gt; &lt;h2&gt;Test, Test, and Test Again&lt;/h2&gt; &lt;p&gt;If we run the application tests right now, it fails. First, we need to update the configuration to pass the JDBC URL and related details. But wait&amp;#8230; we also need a database. We don&amp;#8217;t necessarily want to use PostgreSQL in our unit test. Let&amp;#8217;s use HSQL, an in-memory database. To do that we first need to add the following dependency in the &lt;code&gt;pom.xml&lt;/code&gt;:&lt;/p&gt; &lt;pre class="brush: xml; title: ; notranslate"&gt; &amp;#60;dependency&amp;#62; &amp;#60;groupId&amp;#62;org.hsqldb&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;hsqldb&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;2.4.0&amp;#60;/version&amp;#62; &amp;#60;scope&amp;#62;test&amp;#60;/scope&amp;#62; &amp;#60;/dependency&amp;#62; &lt;/pre&gt; &lt;p&gt;But wait, if you already use JDBC or database in general, you know that each database uses a different dialect (that&amp;#8217;s the power of standards). Here, we can&amp;#8217;t use the same table creation statement because HSQL does not understand the PostgreSQL dialect. So create the &lt;code&gt;src/test/resources/tables.sql&lt;/code&gt; with the following content:&lt;/p&gt; &lt;pre class="brush: sql; title: ; notranslate"&gt; CREATE TABLE IF NOT EXISTS Articles (id INTEGER IDENTITY, title VARCHAR(200), url VARCHAR(200)) &lt;/pre&gt; &lt;p&gt;It&amp;#8217;s the equivalent statement in the HSQL dialect. How would that work? When Vert.x reads a file it also checks the &lt;em&gt;classpath&lt;/em&gt; (and &lt;code&gt;src/test/resources&lt;/code&gt; is included in the &lt;em&gt;test classpath&lt;/em&gt;). When running test, this file superseds the initial file we created.&lt;/p&gt; &lt;p&gt;We need to slightly update our tests to configure the &lt;code&gt;JDBCClient&lt;/code&gt;. In the &lt;code&gt;MyFirstVerticleTest&lt;/code&gt; class, change the &lt;code&gt;DeploymentOption&lt;/code&gt; object created in the &lt;code&gt;setUp&lt;/code&gt; method to be:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; DeploymentOptions options = new DeploymentOptions() .setConfig(new JsonObject() .put(&amp;#34;HTTP_PORT&amp;#34;, port) .put(&amp;#34;url&amp;#34;, &amp;#34;jdbc:hsqldb:mem:test?shutdown=true&amp;#34;) .put(&amp;#34;driver_class&amp;#34;, &amp;#34;org.hsqldb.jdbcDriver&amp;#34;) ); &lt;/pre&gt; &lt;p&gt;In addition to the &lt;code&gt;HTTP_PORT&lt;/code&gt;, we also put the JDBC url and the class of the JDBC driver.&lt;/p&gt; &lt;p&gt;Now, you should be able to run the test with: &lt;code&gt;mvn clean test&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Showtime&lt;/h2&gt; &lt;p&gt;This time we want to use a PostgreSQL instance. I&amp;#8217;m going to use docker but use your favorite approach. With docker, I start my instance as follows:&lt;/p&gt; &lt;pre class="brush: bash; title: ; notranslate"&gt; docker run --name some-postgres -e POSTGRES_USER=user \ -e POSTGRES_PASSWORD=password \ -e POSTGRES_DB=my_read_list \ -p 5432:5432 -d postgres &lt;/pre&gt; &lt;p&gt;Let’s now run our application:&lt;/p&gt; &lt;pre class="brush: java; title: ; notranslate"&gt; mvn compile vertx:run &lt;/pre&gt; &lt;p&gt;Open your browser to &lt;a href="http://localhost:8082/assets/index.html"&gt;http://localhost:8082/assets/index.html&lt;/a&gt;, and you&lt;br /&gt; should see the application using the database. This time the products are stored in a database persisted on the file system. So, if we stop and restart the application, the data is restored.&lt;/p&gt; &lt;p&gt;If you want to package the application, run &lt;code&gt;mvn clean package&lt;/code&gt;. Then run the application using:&lt;/p&gt; &lt;pre class="brush: bash; title: ; notranslate"&gt; java -jar target/my-first-app-1.0-SNAPSHOT.jar \ -conf src/main/conf/my-application-conf.json &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This fourth post in our series has covered two topics. First, we have introduced asynchronous composition and how &lt;code&gt;Future&lt;/code&gt; helps to manage sequential and concurrent composition. With &lt;code&gt;Future&lt;/code&gt;, you follow a common pattern in your implementation, which is quite straightforward once you get it. Secondly, we have seen how JDBC can be used to implement our API. Because we use &lt;code&gt;Future&lt;/code&gt;, using asynchronous JDBC is quite simple.&lt;/p&gt; &lt;p&gt;You may have been surprised by the asynchronous development model, but once you start using it, it’s hard to come back. Asynchronous and event-driven architecture represents how the world around us works. Embracing these give you superpowers.&lt;/p&gt; &lt;p&gt;In the next post, we will see how RX Java 2 can be used instead of Future. Don’t forget that the code is available in this &lt;a href="https://github.com/redhat-developer/introduction-to-eclipse-vertx"&gt;Github repository.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Stay tuned, and happy coding!&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Faccessing-data-reactive-way%2F&amp;#38;linkname=Accessing%20Data%20%E2%80%93%20The%20Reactive%20Way" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Faccessing-data-reactive-way%2F&amp;#38;linkname=Accessing%20Data%20%E2%80%93%20The%20Reactive%20Way" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Faccessing-data-reactive-way%2F&amp;#38;linkname=Accessing%20Data%20%E2%80%93%20The%20Reactive%20Way" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Faccessing-data-reactive-way%2F&amp;#38;linkname=Accessing%20Data%20%E2%80%93%20The%20Reactive%20Way" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Faccessing-data-reactive-way%2F&amp;#38;linkname=Accessing%20Data%20%E2%80%93%20The%20Reactive%20Way" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Faccessing-data-reactive-way%2F&amp;#38;linkname=Accessing%20Data%20%E2%80%93%20The%20Reactive%20Way" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Faccessing-data-reactive-way%2F&amp;#38;linkname=Accessing%20Data%20%E2%80%93%20The%20Reactive%20Way" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Faccessing-data-reactive-way%2F&amp;#38;linkname=Accessing%20Data%20%E2%80%93%20The%20Reactive%20Way" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Faccessing-data-reactive-way%2F&amp;#38;title=Accessing%20Data%20%E2%80%93%20The%20Reactive%20Way" data-a2a-url="https://developers.redhat.com/blog/2018/04/09/accessing-data-reactive-way/" data-a2a-title="Accessing Data – The Reactive Way"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/09/accessing-data-reactive-way/"&gt;Accessing Data &amp;#8211; The Reactive Way&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Ilmh64d6DhY" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This is the fourth post of my &amp;#8220;Introduction to Eclipse Vert.x.&amp;#8221; series. In this article, we are going to see how we can use JDBC in an Eclipse Vert.x application using the asynchronous API provided by the vertx-jdbc-client. But before diving into JDBC and other SQL subtleties, we are going to talk about Vert.x Futures. In [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/09/accessing-data-reactive-way/"&gt;Accessing Data &amp;#8211; The Reactive Way&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/04/09/accessing-data-reactive-way/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">478367</post-id><dc:creator>Clement Escoffier</dc:creator><dc:date>2018-04-09T18:03:58Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/04/09/accessing-data-reactive-way/</feedburner:origLink></entry><entry><title>Byteman 4.0.2 has been released</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/UJloShibKas/byteman-402-has-been-released.html" /><category term="feed_group_name_byteman" scheme="searchisko:content:tags" /><category term="feed_name_byteman" scheme="searchisko:content:tags" /><author><name>Andrew Dinn</name></author><id>searchisko:content:id:jbossorg_blog-byteman_4_0_2_has_been_released</id><updated>2018-04-09T15:53:00Z</updated><published>2018-04-09T15:53:00Z</published><content type="html">&lt;div class="post-body entry-content" id="post-body-3028514058787793602" itemprop="description articleBody"&gt;Byteman 4.0.2 is now available from the &lt;a class="moz-txt-link-freetext" href="http://www.jboss.org/byteman/downloads"&gt;Byteman downloads page&lt;/a&gt; and from the &lt;a class="moz-txt-link-freetext" href="https://oss.sonatype.org/index.html#nexus-search;quick%7Ebyteman"&gt;Maven Central repository&lt;/a&gt;. It is the latest release for use on JDK9+ runtimes. It is also recommended as the preferred release for use on JDK8- runtimes.&lt;/div&gt;&lt;div class="post-body entry-content" id="post-body-3028514058787793602" itemprop="description articleBody"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="post-body entry-content" id="post-body-3028514058787793602" itemprop="description articleBody"&gt;Byteman 4.0.2 updates the 4.0.1 release with a small number of bug fixes and performance improvements. More details can be found in the &lt;a href="http://downloads.jboss.org/byteman/4.0.2/ReleaseNotes.txt"&gt;Release Notes&lt;/a&gt;.&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/UJloShibKas" height="1" width="1" alt=""/&gt;</content><summary>Byteman 4.0.2 is now available from the Byteman downloads page and from the Maven Central repository. It is the latest release for use on JDK9+ runtimes. It is also recommended as the preferred release for use on JDK8- runtimes. Byteman 4.0.2 updates the 4.0.1 release with a small number of bug fixes and performance improvements. More details can be found in the Release Notes.</summary><dc:creator>Andrew Dinn</dc:creator><dc:date>2018-04-09T15:53:00Z</dc:date><feedburner:origLink>http://bytemanblog.blogspot.com/2018/04/byteman-402-has-been-released.html</feedburner:origLink></entry><entry><title>A Cloud Lab Environment in a Backpack</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Ie8KI-jS-w0/" /><category term="Cloud" /><category term="OpenStack" /><category term="Red Hat OpenShift Container Platform" /><category term="Ansible" /><category term="DevOps" /><category term="nuc shell" /><category term="OpenShift Container Platform" /><category term="OpenShift Enterprise by Red Hat" /><category term="Red Hat Enterprise Linux" /><author><name>Marcelo "Ataxexe" Guimarães</name></author><id>https://developers.redhat.com/blog/?p=475497</id><updated>2018-04-09T10:55:53Z</updated><published>2018-04-09T10:55:53Z</published><content type="html">&lt;p&gt;Have you ever thought about having your own cloud environment? A local cloud is one of the best things you can do to better understand all the gears that run inside a highly productive environment. How do I know that? I&amp;#8217;ve done it! And I&amp;#8217;m ready to show you how I did, and how you can do it too.&lt;/p&gt; &lt;p&gt;&lt;span id="more-475497"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Beep, beep! The alarm just sounded. It’s 4 a.m. and I can’t even feel my thoughts. I&amp;#8217;ve got to leave without making noise. Luckily the airport is not so far from home.&lt;/p&gt; &lt;p&gt;I’m often traveling around the country showing a lot of stuff about DevOps, focusing on the &lt;a href="https://developers.redhat.com/products/openshift/overview/"&gt;Red Hat OpenShift Container Platform&lt;/a&gt;. It’s great work, but it has its risks. Since I don’t know exactly what the environment is where I will have to present, I’m constantly surrounded by many challenges: networks full of policies and proxies, buildings without reliable mobile Internet access, mobile quota exceeded, poor hotel Internet access; the list keeps growing. Having a lot of resources on the cloud can’t solve my problem if I can’t connect to the cloud. This is prone to disaster.&lt;/p&gt; &lt;p&gt;I can’t depend on cloud providers. I had to be my own cloud provider.&lt;/p&gt; &lt;p&gt;I have a great friend who happens to be a digital nomad like me. He is one of the best companions ever. There was a day we were browsing the Internet looking for a “Raspberry on steroids”. After finding a lot of tiny and powerful devices, he spotted our winner: the &lt;a href="https://www.intel.com/content/www/us/en/nuc/nuc-kit-nuc6i7kyk-features-configurations.html"&gt;Intel Nuc Skull Canyon&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;I told him: “One day I’ll have one of these. Imagine how great it will be to arrive at a customer’s site showing off this cute piece of hardware.”&lt;/p&gt; &lt;p&gt;This wasn’t the first time Claudio found a great piece of hardware. I’ve been using a &lt;a href="http://gl-inet.com/"&gt;GL.iNet&lt;/a&gt; router recommended by him (the GL-AR300M model). But the Nuc was Claudio’s biggest discovery. It instantly became the highest priority item on my buying list. After months of saving, I was finally able to buy a Nuc with an astonishing 32GB of RAM, plus 1TB of SSD. The next step was supposed to be simple: running Red Hat OpenShift on it.&lt;/p&gt; &lt;p&gt;In the beginning, I was using the classic &lt;code class="highlighter-rouge"&gt;oc cluster up&lt;/code&gt;. It spawns an unstoppable beast that runs really smooth on such hardware. It was fast, but not fun. Especially because metrics and logging didn’t work. Some issues in the deployer pods prevented them from succeeding. I ended up writing a &lt;a href="https://www.redhat.com/en/technologies/management/ansible"&gt;Red Hat Ansible Automation&lt;/a&gt; playbook to fix those issues using the &lt;code class="highlighter-rouge"&gt;oc debug&lt;/code&gt; command. It was functional, but definitely not fun.&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.redhat.com/en/technologies/linux-platforms/openstack-platform"&gt;Red Hat OpenStack Platform&lt;/a&gt; sounded like a lot of fun to me, however installing it through Red Hat OpenStack Director on the Nuc wasn’t a feasible task. So, I went with the easy-peasy &lt;a href="https://wiki.openstack.org/wiki/Packstack"&gt;Packstack&lt;/a&gt; (please, don’t kill me).&lt;/p&gt; &lt;p&gt;Well… not so easy for a developer like me, who had near zero experience with network stuff.&lt;/p&gt; &lt;p&gt;After a lot of trial and error, I finally managed to configure Red Hat OpenStack Platform. Since &amp;#8220;stuff&amp;#8221; happens, I wrote a playbook to bring it up with a lab project containing all the stuff I needed to play with it. Then I made the whole thing available on &lt;a href="https://github.com/devnull-tools/pack-your-lab/tree/master/openstack"&gt;GitHub&lt;/a&gt;. “The fun has begun.”&lt;/p&gt; &lt;p&gt;Ok! I had a way to install Red Hat OpenStack Platform, but how about installing Red Hat Enterprise Linux? Some web pages later I found the Anaconda’s Kickstart. It’s a way of automating the RHEL installation (and any other Linux distribution installed through Anaconda). Even better, RHEL writes a kickstart file after every installation. Then you just have to copy and paste the file to a drive named OEMDRV. Two flash drives (one with the RHEL image and the other with the Kickstart file) would trigger the automated install. But I didn’t want to use flash drives, I had two unused Android devices. Even more fun.&lt;/p&gt; &lt;p&gt;I’ve been using Android devices since 2010; my first one was a Motorola Quench running Android 1.5 (Cupcake). When I rooted it and saw the endless possibilities, my mind opened and I became fascinated by using Android devices for everything.&lt;/p&gt; &lt;p&gt;I started to search for a way to use an Android device as a flash drive, which led me to the awesome &lt;a href="https://play.google.com/store/apps/details?id=com.softwarebakery.drivedroid"&gt;DriveDroid;&lt;/a&gt; it’s an app that emulates both flash drives and CD-ROM drives. I took my phones and loaded one with the RHEL image, the other with the Kickstart image, then I plugged both into the rear USB ports. I didn’t care about the battery because they were old phones.&lt;/p&gt; &lt;p&gt;So I thought: “Now I have two phones; just for installing RHEL? Why don’t I use them for something else?” Two Android devices can make a difference in the setup. I installed the fantastic &lt;a href="https://play.google.com/store/apps/details?id=com.icecoldapps.serversultimatepro"&gt;Servers Ultimate&lt;/a&gt; on both phones to reduce the workload on the Nuc. Smb sharing on both phones allowed me to upload any new image I wanted to install; which led me to put in an HTTP server to serve installation files for my Docker images. A git server would do the rest of the trick by holding my inventory files for my open-sourced Red Hat Ansible Automation playbooks.&lt;/p&gt; &lt;p&gt;To finish up, I plugged the router into the USB-C port. The router takes some time to boot up (more time than the Nuc). This causes a network issue with the Nuc because the Red Hat OpenStack Platform needs Network Manager disabled, so the network needs to be available before the Nuc boots up. By attaching the router on the USB-C port, it can be powered without the Nuc itself being on. Then I’ve attached all cables and left the Nuc to be ready just by plugging in the power supply. Hook and loop fasteners completed the design, holding the Android devices and the router on top of the Nuc. Then it’s easy to put the package in a little handbag, which I need to open every time I go to the airport because its image on the x-ray is similar to a bomb! I’ve discovered this in the worst possible way.&lt;/p&gt; &lt;p&gt;Installing RHEL with the Red Hat OpenStack Platform (plus a fully working project) was only a matter of seven steps:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Run DriveDroid on both phones.&lt;/li&gt; &lt;li&gt;Turn on the Nuc.&lt;/li&gt; &lt;li&gt;Wait until a push notification arrives at my main phone.&lt;/li&gt; &lt;li&gt;Shutoff DriveDroid.&lt;/li&gt; &lt;li&gt;Turn on the Nuc again.&lt;/li&gt; &lt;li&gt;Run the Red Hat Ansible Automation playbook to install Red Hat OpenStack Platform.&lt;/li&gt; &lt;li&gt;Wait until the second push notification arrives.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;My Kickstart script turns off the Nuc after writing my ssh public key into the authorization keys and sending a notification through &lt;a href="https://pushover.net/"&gt;Pushover&lt;/a&gt;. I’ve been using Pushover for some time; it’s a straightforward way to get notified. That second push notification means a lot to me; it tells me my cloud environment is ready.&lt;/p&gt; &lt;figure id="attachment_475517" style="max-width: 640px" class="wp-caption aligncenter"&gt;&lt;img class="wp-image-475517 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/03/nuc-1024x310.png" alt="My Portable Cloud" width="640" height="194" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/03/nuc-1024x310.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/03/nuc-300x91.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/03/nuc-768x232.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;figcaption class="wp-caption-text"&gt;My Portable Cloud&lt;/figcaption&gt;&lt;/figure&gt; &lt;p&gt;I finally managed to be my own cloud provider. With a lot of fun, and not a single drop of rum!&lt;/p&gt; &lt;p&gt;The next step, installing Red Hat OpenShift, wasn’t easy. After a lot of issues while running the playbook, I found the problem. The router (the GL-AR300M) is a great router, but it’s not a router for receiving the traffic of a PaaS. So I decided to create an internal DNS as an OpenStack instance.&lt;/p&gt; &lt;p&gt;From my laptop, I was using the external IP addresses. However, internally the instances will be talking with each other using only internal IP addresses instead of the external ones. A classic mistake for a developer like me.&lt;/p&gt; &lt;p&gt;With everything settled, I ran the playbook again… and got another error. Red Hat OpenShift wasn’t being able to talk with Red Hat OpenStack Platform in order to create volumes in Cinder to attach them to the nodes running pods. The problem was solved upstream; a single line telling Red Hat OpenShift to use the version &lt;code class="highlighter-rouge"&gt;v2&lt;/code&gt; of the Red Hat OpenStack Block Storage API. So I wrote a little workaround to apply the fix to OCP 3.7, and wrapped up everything in a playbook and pushed to &lt;a href="https://github.com/devnull-tools/pack-your-lab/tree/master/openshift"&gt;GitHub&lt;/a&gt;. With OCP 3.9 applying the fix from the upstream, I don’t need my custom fix anymore, just the regular playbooks.&lt;/p&gt; &lt;p&gt;The playbook can create all the instances with the Docker Storage mapped to a Cinder volume, all prereqs done and the Red Hat Ansible inventory file created, neat! With a single step, I was able to bring up a Red Hat OpenShift cluster. I ran it a lot of times on a weekend just to see things going on. That was “gigafun”!&lt;/p&gt; &lt;p&gt;With the cloud environment done, it was just a matter of installing the tools for my presentations. But the environment was so great that I’ve decided to bring my own working environment to it. My presentations became real case scenarios!&lt;/p&gt; &lt;p&gt;I don’t like to put labels on developers: backend, frontend, full stack…, it sounds like different types of heavy metal music. It’s all about coding, but one can have more expertise in some areas.&lt;/p&gt; &lt;p&gt;I love coding and I try to learn many programming languages. They’re tools. If you have the right tool for the job, you can get the job done with pleasure (and fun). That’s why I also love to code tools to get better at getting my job done. So, my work environment is quite easy to reproduce: a &lt;a href="https://gitlab.com/"&gt;GitLab&lt;/a&gt; instance and a &lt;a href="https://www.sonatype.com/nexus-repository-sonatype"&gt;Nexus&lt;/a&gt; Repository. But that doesn’t mean I don’t have a value stream to deliver my tools.&lt;/p&gt; &lt;p&gt;I was abducted by the GitLab Runner. It’s fantastic! My &lt;a href="https://gogs.io/"&gt;Gogs&lt;/a&gt; instance went down and I never looked back. Don’t get me wrong, Gogs is a wonderful project, but the GitLab Runner provided me the best tool to get my job done (aka fun).&lt;/p&gt; &lt;p&gt;The runner is a connection between your code and your value stream (the pipeline). Every step on the pipeline runs inside a container created by the runner on top of Red Hat OpenShift. I created a set of build images to not only compile my code but also to release it. Pushover tells me everything about my pipeline. Everything now happens in a wonderful and powerful integration that helps me to engage people.&lt;/p&gt; &lt;p&gt;There are tons of ways to do something, but the way you show how it’s done is what engages people. It’s how magic is done!&lt;/p&gt; &lt;p&gt;A good card trick is straightforward. It doesn’t matter how you ask people to pick a card, or how nicely you shuffle the deck. In the end, it’s all about how you reveal the card. If you do it right, it will be unforgettable.&lt;/p&gt; &lt;p&gt;I love card tricks! You can easily engage an audience with a good trick and that’s how I do my presentations nowadays. They don’t expect me to come up with a little device and throw up an entire environment ready to rock. It’s my best trick! The fun-o-meter blew off!&lt;/p&gt; &lt;p&gt;Oh! My cab is almost here, I should probably finish my coffee. I have a presentation to do… and the best environment is now at my side.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Fcloud-lab-environment%2F&amp;#38;linkname=A%20Cloud%20Lab%20Environment%20in%20a%20Backpack" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Fcloud-lab-environment%2F&amp;#38;linkname=A%20Cloud%20Lab%20Environment%20in%20a%20Backpack" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Fcloud-lab-environment%2F&amp;#38;linkname=A%20Cloud%20Lab%20Environment%20in%20a%20Backpack" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Fcloud-lab-environment%2F&amp;#38;linkname=A%20Cloud%20Lab%20Environment%20in%20a%20Backpack" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Fcloud-lab-environment%2F&amp;#38;linkname=A%20Cloud%20Lab%20Environment%20in%20a%20Backpack" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Fcloud-lab-environment%2F&amp;#38;linkname=A%20Cloud%20Lab%20Environment%20in%20a%20Backpack" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Fcloud-lab-environment%2F&amp;#38;linkname=A%20Cloud%20Lab%20Environment%20in%20a%20Backpack" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Fcloud-lab-environment%2F&amp;#38;linkname=A%20Cloud%20Lab%20Environment%20in%20a%20Backpack" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F09%2Fcloud-lab-environment%2F&amp;#38;title=A%20Cloud%20Lab%20Environment%20in%20a%20Backpack" data-a2a-url="https://developers.redhat.com/blog/2018/04/09/cloud-lab-environment/" data-a2a-title="A Cloud Lab Environment in a Backpack"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/09/cloud-lab-environment/"&gt;A Cloud Lab Environment in a Backpack&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Ie8KI-jS-w0" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Have you ever thought about having your own cloud environment? A local cloud is one of the best things you can do to better understand all the gears that run inside a highly productive environment. How do I know that? I&amp;#8217;ve done it! And I&amp;#8217;m ready to show you how I did, and how you [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/09/cloud-lab-environment/"&gt;A Cloud Lab Environment in a Backpack&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/04/09/cloud-lab-environment/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">475497</post-id><dc:creator>Marcelo "Ataxexe" Guimarães</dc:creator><dc:date>2018-04-09T10:55:53Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/04/09/cloud-lab-environment/</feedburner:origLink></entry></feed>
